<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.5.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2018-07-27T11:47:27+02:00</updated><id>http://localhost:4000/</id><title type="html">sambaiga</title><author><name>Anthony Faustine</name></author><entry><title type="html">Building Tomorrow’s AI leaders in Tanzania</title><link href="http://localhost:4000/ml/deep%20learning/probability/2018/07/22/building_tomorrow_ai_leaders.html" rel="alternate" type="text/html" title="Building Tomorrow's AI leaders in Tanzania" /><published>2018-07-22T17:12:00+02:00</published><updated>2018-07-27T11:46:49+02:00</updated><id>http://localhost:4000/ml/deep%20learning/probability/2018/07/22/building_tomorrow_ai_leaders</id><content type="html" xml:base="http://localhost:4000/ml/deep%20learning/probability/2018/07/22/building_tomorrow_ai_leaders.html">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;&quot;&gt;Pythontz&lt;/a&gt; in collaboration with &lt;a href=&quot;&quot;&gt;parrotai&lt;/a&gt; is hosting a six weeks  intesnive training in machine intelligence for students. The training is designed to help students grasp both theoretical and practical foundations of machine learning. A detailed weekly program for this training is as follows:&lt;/p&gt;

&lt;h3 id=&quot;week-1-machine-learning-fundamentals&quot;&gt;Week 1: Machine learning fundamentals&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;Basics of Python for ML and DS Project.
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://github.com/sambaiga/PytzMLS2018/tree/master/Python%20for%20ML%20and%20DS&quot;&gt;Python for ML and DS&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://am207.github.io/2018spring/wiki/pythonlab.html&quot;&gt;An introduction to Objects and their Classes in python&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Selected MOOC &amp;amp; online courses.
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://speakerdeck.com/sambaiga/machine-learning-fundamentals&quot;&gt;Foundation of Machine Learning by sambaiga&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.coursera.org/learn/machine-learning#syllabus&quot;&gt;ML by Andrew Ng week 1, 2 and 3&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.coursera.org/learn/decision-making&quot;&gt;Data-driven Decision Making&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Book chapter.
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://github.com/ageron/handson-ml&quot;&gt;Hands-on Machine Learning with Scikit-Learn and TensorFlow chapter 1,2,3 and 4&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://github.com/amueller/introduction_to_ml_with_python&quot;&gt;Introduction to Machine Learning with Python A Guide for Data Scientists chapter 1, 2 and 4&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;&quot;&gt;Deep Learning with Python by FRANÇOIS CHOLLET chapter 1 and 4&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Lab work&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;week-2-deep-learning-and-computer-vision&quot;&gt;Week 2: Deep learning and Computer Vision&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;Foundations of Deep learning
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://speakerdeck.com/sambaiga/foundation-of-deep-learning&quot;&gt;Foundation of Deep learning by sambaiga&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.coursera.org/learn/deep-neural-network&quot;&gt;Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://cs231n.stanford.edu/syllabus.html&quot;&gt;CS231n: Training Neural Networks, part I and II&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Deep learning frameworks
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.coursera.org/learn/ai&quot;&gt;Applied AI with DeepLearning week 3&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://cs231n.stanford.edu/slides/2018/cs231n_2018_lecture08.pdf&quot;&gt;CS231n: Deep Learning Hardware and Software&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Computer vision (CNN)
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://speakerdeck.com/sambaiga/deep-learning-for-computer-vision&quot;&gt;Deep learning for computer vision by sambaiga&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://www.di.ens.fr/~lelarge/dldiy/&quot;&gt;Deep Learning: Do-It-Yourself (lecture 6&amp;amp;7)&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.coursera.org/learn/convolutional-neural-networks&quot;&gt;Deep learning specialization Andrew Ng: CNN&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.coursera.org/learn/deep-learning-in-computer-vision&quot;&gt;Deep Learning in Computer Vision (focus week 3,4 and 5)&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Lab work
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://github.com/sambaiga/PytzMLS2018/tree/master/Lab-4&quot;&gt;IndabaX Tanzania Lab 4&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;week-3-sequence-model-and-recommender-systems&quot;&gt;Week 3: Sequence model and Recommender systems&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;Sequence Models and NLP
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;http://www.di.ens.fr/~lelarge/dldiy/&quot;&gt;Deep Learning: Do-It-Yourself (lecture 8)&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://www.di.ens.fr/~lelarge/dldiy/&quot;&gt;CMSC 35246 Deep Learning (lecture 6)&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.coursera.org/learn/nlp-sequence-models#syllabus&quot;&gt;Deep learning specialization Andrew Ng: Sequence model&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Recommender systems
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.coursera.org/learn/recommender-systems-introduction&quot;&gt;Introduction to Recommender Systems&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Building machine learning project
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.coursera.org/learn/machine-learning-projects&quot;&gt;Structuring Machine Learning Projects&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Lab work&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;week-4-practical-machine-learning-1&quot;&gt;Week 4: Practical machine learning 1&lt;/h3&gt;
&lt;p&gt;Choose two tracks: track 1 is mandatory.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Winning Kaggle challenge
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.coursera.org/learn/competitive-data-science&quot;&gt;How to Win a Data Science Competition: Learn from Top Kagglers&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Computer vision
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;http://course.fast.ai/part2.html&quot;&gt;Fast ai lessons 8, 9 and 10&lt;/a&gt;: &lt;a href=&quot;https://medium.com/@hiromi_suenaga&quot;&gt;Hiromi Suenaga notes&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Sequence model and recommender systems
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;http://course.fast.ai/&quot;&gt;Fast ai lesson 4, 5, 6&lt;/a&gt;: &lt;a href=&quot;https://medium.com/@hiromi_suenaga&quot;&gt;Hiromi Suenaga notes&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.kaggle.com/c/web-traffic-time-series-forecasting/discussion/43795&quot;&gt;Web Traffic Time Series Forecasting&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;week-5-practical-machine-learning-ii&quot;&gt;Week 5: Practical machine learning II&lt;/h3&gt;
&lt;p&gt;Choose two tracks: track 1 is mandatory.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;General machine learning
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.kaggle.com/c/santander-customer-satisfaction/discussion/20978&quot;&gt;Santander Customer Satisfaction: Which customers are happy customers?&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://github.com/flowlight0/talkingdata-adtracking-fraud-detection&quot;&gt;TalkingData AdTracking Fraud Detection Challenge: Can you detect fraudulent click traffic for mobile app ads?&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Computer vision
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;http://course.fast.ai/part2.html&quot;&gt;Fast ai lesson 8, 9 and 10&lt;/a&gt;: &lt;a href=&quot;https://medium.com/@hiromi_suenaga&quot;&gt;Hiromi Suenaga notes&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Sequence models
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;http://course.fast.ai/part2.html&quot;&gt;Fast ai lesson 10 and 11&lt;/a&gt;: &lt;a href=&quot;https://medium.com/@hiromi_suenaga&quot;&gt;Hiromi Suenaga notes&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;week-6-basics-of-probabilistic-methods-for-machine-learning&quot;&gt;Week 6: Basics of probabilistic methods for machine learning&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;Selected MOOC and online courses
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.coursera.org/learn/bayesian-methods-in-machine-learning&quot;&gt;Bayesian Methods for Machine Learning (week 1 and 2)&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://www.cs.toronto.edu/~rgrosse/courses/csc321_2018/&quot;&gt;Lecture 18: Learning Probabilistic Models&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://sambaiga.github.io/ml/deep%20learning/probability/2018/06/08/deepprobabilistic_1.html&quot;&gt;Basics of Probability and Information Theory&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://sambaiga.github.io/ml/deep%20learning/probability/2018/06/28/deepprobabilistic_2.html&quot;&gt;Bayesian Inference by sambaiga&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Book chapter
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;http://www.stat.columbia.edu/~gelman/book/&quot;&gt;Bayesian Data Analysis by Andrew Gelman chapter 1&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers&quot;&gt;Bayesian Methods for Hackers chapter 1&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;</content><author><name>Anthony Faustine</name></author><summary type="html">Introduction</summary></entry><entry><title type="html">Bayesian Inference</title><link href="http://localhost:4000/ml/deep%20learning/probability/2018/06/28/deepprobabilistic_2.html" rel="alternate" type="text/html" title="Bayesian Inference" /><published>2018-06-28T17:12:00+02:00</published><updated>2018-07-26T13:37:09+02:00</updated><id>http://localhost:4000/ml/deep%20learning/probability/2018/06/28/deepprobabilistic_2</id><content type="html" xml:base="http://localhost:4000/ml/deep%20learning/probability/2018/06/28/deepprobabilistic_2.html">&lt;h2 id=&quot;1-introduction&quot;&gt;1. Introduction&lt;/h2&gt;

&lt;p&gt;Bayesian method offer a different paradigm for doing statistical analysis. It is practical method for making inferences from data using probability models. Unlike other statistical approach, bayesian models are easy to interpret and incorporate uncertainty. In bayesian method  we start with a belief which is also called a &lt;strong&gt;prior&lt;/strong&gt;. We then update our belief after observing some data. The outcome is called a &lt;strong&gt;posterior&lt;/strong&gt;. The process repeats as we keep on observing more data where the old &lt;em&gt;posterior&lt;/em&gt; becomes a new &lt;em&gt;prior&lt;/em&gt;. The  process employs the Bayes rule.&lt;/p&gt;

&lt;p&gt;Consider the Bayesian theorem, which allows us to use some knowledge or belief that we already have. Given data point &lt;script type=&quot;math/tex&quot;&gt;\mathcal{D} = \{x \in \mathbb{R}^{N\times d}, y \in \mathbb{R}^{N\times c}\}&lt;/script&gt;. The Bayesian  approach  treat the latent variable or parameter &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; as random variable with some prior distribution &lt;script type=&quot;math/tex&quot;&gt;p(z)&lt;/script&gt;. This is the probability of parameters &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; before hand.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(z | \mathcal{D}  ) = \frac{p(\mathcal{D} | z )\cdot p(z)}{p(\mathcal{D})}&lt;/script&gt;

&lt;p&gt;where&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(\mathcal{D}) = \int p(\mathcal{D} |z )\cdot p(z) dz&lt;/script&gt;

&lt;p&gt;From the bayesian theorem above,  &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; is the hypothesis about the world, and &lt;script type=&quot;math/tex&quot;&gt;\mathcal{D}&lt;/script&gt; is the data or evidence. The probability &lt;script type=&quot;math/tex&quot;&gt;p(\mathcal{D} \mid z)&lt;/script&gt; is called  &lt;strong&gt;likeli-hood&lt;/strong&gt;; the probability of data given the latent variable and &lt;script type=&quot;math/tex&quot;&gt;p(\mathcal{D})&lt;/script&gt; is the &lt;strong&gt;marginal-likelihood&lt;/strong&gt; and &lt;script type=&quot;math/tex&quot;&gt;p(z \mid \mathcal{D}  )&lt;/script&gt; is the &lt;strong&gt;posterior&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;11-bayesian-inference&quot;&gt;1.1 Bayesian Inference&lt;/h3&gt;

&lt;p&gt;Given data set &lt;script type=&quot;math/tex&quot;&gt;\mathcal{D}&lt;/script&gt; and latent variable &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; that relate &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;y&lt;/script&gt; such that:
&lt;script type=&quot;math/tex&quot;&gt;y = f_{z}(x:z)&lt;/script&gt;
The first step in bayesian inference is to identify the parameter &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; and express our lack of knowledge  about this parameter in term of probability distribution &lt;script type=&quot;math/tex&quot;&gt;p(z)&lt;/script&gt;. This is the prior knowledge about the parameter &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt;. After that we express a &lt;em&gt;likelihood&lt;/em&gt;  &lt;script type=&quot;math/tex&quot;&gt;p(\mathcal{D} \mid z)&lt;/script&gt; which tell us how the data &lt;script type=&quot;math/tex&quot;&gt;\mathcal{D}&lt;/script&gt; interact with  parameter &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt;. Together the prior and the likelihood make our model (generative model). It tell us how we can simulate from our data.&lt;/p&gt;

&lt;p&gt;In &lt;strong&gt;training&lt;/strong&gt; stage we apply Bayesian theorem to get posterior distribution:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(z|\mathcal{D}) = \frac{p(\mathcal{D}|, z)}{p(\mathcal{D})}&lt;/script&gt;

&lt;p&gt;In testing stage we find &lt;strong&gt;predictive-distribution&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(\hat{y}| x, \mathcal{D}) = \int p(\hat{y} | x, z)\cdot p(z | x, y) dz&lt;/script&gt;

&lt;p&gt;Theoretically this is how bayesian inference work, however the big challenge is how to compute the posterior distribution. The integral &lt;script type=&quot;math/tex&quot;&gt;\int p(\mathcal{D} \mid z )\cdot p(z) dz&lt;/script&gt; is usually intractable. Therefore we need to approximate this integral. There several approach used for approximation. The first and simple approach is to use &lt;em&gt;analytical integration&lt;/em&gt; which is only applicable with the use of &lt;a href=&quot;https://en.wikipedia.org/wiki/Conjugate_prior&quot;&gt;conjugate prior&lt;/a&gt; and thus possible only for very simple cases. However the approach does not scale well. Alternatively &lt;em&gt;&lt;a href=&quot;https://metacademy.org/graphs/concepts/laplace_approximation&quot;&gt;Gaussian (Laplace) approximation&lt;/a&gt;&lt;/em&gt; can be applied where the posterior is  approximated  with Gaussian. This works well when there are lot of data. &lt;a href=&quot;https://metacademy.org/graphs/concepts/markov_chain_monte_carlo&quot;&gt;Markov Chain Monte Carlo (MCMC)&lt;/a&gt; are among other popular techniques used for approximating the integral. The method is applicable to wide variety of problems however is very slow.&lt;/p&gt;

&lt;p&gt;The popular and recently widely used approach for approximating prior in bayesian method is &lt;em&gt;Variational Inference&lt;/em&gt;. This approach convert the integral into optimization problem and thus Work faster than MCMC. In this post we will introduce the basic concepts behind variational inference and different algorithms for performing variation inferences. For dive into varitiaonl infrence let us revisit one example of bayesian inference in regression problem.&lt;/p&gt;

&lt;h3 id=&quot;12-bayesian-linear-regression&quot;&gt;1.2 Bayesian Linear Regression&lt;/h3&gt;
&lt;p&gt;Given data point &lt;script type=&quot;math/tex&quot;&gt;X = \{x_1,\ldots x_N \}&lt;/script&gt; and corresponding target &lt;script type=&quot;math/tex&quot;&gt;Y = \{y_1,\ldots y_N \}&lt;/script&gt;. Linear regression assume that data is generated from the following model:&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;y= f_{\theta}(x: \theta) + \in&lt;/script&gt;
 where &lt;script type=&quot;math/tex&quot;&gt;\in&lt;/script&gt; is the noise due to measurement and 
&lt;script type=&quot;math/tex&quot;&gt;f_{\theta}(X: \theta)&lt;/script&gt; is the hypothesis function given;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f_{\theta}(X: \theta) = b + \sum_{i=1}^N w_i \phi (x_i) = \theta^T\cdot \phi(X)&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;\phi(X)&lt;/script&gt; is the basis function and &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt; is the model parameters such that 
&lt;script type=&quot;math/tex&quot;&gt;\theta_{0} =b&lt;/script&gt;  and &lt;script type=&quot;math/tex&quot;&gt;\phi_0=1&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;The  output of this model is the single point estimate for the best model parameter. The Bayesian modelling approach to this problem offer a systematic framework for learning distribution over values of the parameters and not a single estimate. The bayesian linear regression model &lt;script type=&quot;math/tex&quot;&gt;y= f_{\theta}(x: \theta) + \in&lt;/script&gt; as a Gaussian  distribution such that:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(y|x, \theta) = \mathcal{N}(y|f_{\theta}(x: \theta), \beta^{-1})&lt;/script&gt;

&lt;p&gt;Assuming the data point are drawn independently and identically distributed the likelihood is expressed as:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(Y| X, \theta) = \prod_{i=1}^N \mathcal{N}(y_i|f_{\theta}(x_i: \theta_i), \beta^{-1})&lt;/script&gt;

&lt;p&gt;Let choose a prior that is conjugate to the likelihood&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(\theta|X) = \mathcal{N}(\theta|0, \alpha^{-1})&lt;/script&gt;

&lt;p&gt;Thus the posterior is given as:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(\theta|Y, X) \propto \mathcal{N}(\theta|0, \alpha^{-1})\cdot \prod_{i=1}^N \mathcal{N}(y_i|f_{\theta}(x_i: \theta_i), \beta^{-1})&lt;/script&gt;

&lt;h2 id=&quot;2-variational-inference&quot;&gt;2. Variational Inference&lt;/h2&gt;
&lt;p&gt;In the previous section we show that inference in probabilist model is often intractable and introduced several approach used to approximate the inference. Variational Inference (VI) is one of the approach used to approximate difficult probability distribution by turning the calculation about model into optimization.&lt;/p&gt;

&lt;p&gt;Consider a probabilistic model which is joint distribution &lt;script type=&quot;math/tex&quot;&gt;p(x,z)&lt;/script&gt; of the latent variable  &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; observed variables &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;. To draw inference on the latent variable &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; we compute the posterior&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(z|x) = \frac{p(x,z)}{p(x)} = \frac{p(x|z)\cdot p(z)}{p(x)}&lt;/script&gt;

&lt;p&gt;where&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(x)=\int p(x|z)\cdot p(z) dz&lt;/script&gt;

&lt;p&gt;To approximate &lt;script type=&quot;math/tex&quot;&gt;p(z\mid x)&lt;/script&gt; we first choose an approximating family of distribution &lt;script type=&quot;math/tex&quot;&gt;q(z)&lt;/script&gt; over latent variable  &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt;. Then we find set of parameters that makes &lt;script type=&quot;math/tex&quot;&gt;q(z)&lt;/script&gt; close to posterior distribution &lt;script type=&quot;math/tex&quot;&gt;p(z\mid x)&lt;/script&gt;. Thus VI approximate &lt;script type=&quot;math/tex&quot;&gt;p(z\mid x)&lt;/script&gt; with new distribution &lt;script type=&quot;math/tex&quot;&gt;q(z)&lt;/script&gt; such that &lt;script type=&quot;math/tex&quot;&gt;q(z)&lt;/script&gt; is close to &lt;script type=&quot;math/tex&quot;&gt;p(z\mid x)&lt;/script&gt;. To achieve this we minimize KL divergence between &lt;script type=&quot;math/tex&quot;&gt;q(z)&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;p(z\mid x)&lt;/script&gt; such that:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;q^*(z) = \arg \min D_{KL}(q(z)||p(z|x))&lt;/script&gt;

&lt;p&gt;where&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;D_{KL}(q(z)||p(z|x)) = \int q(z)\log \frac{q(z)}{p(z|x)}&lt;/script&gt;

&lt;p&gt;It clear that we can not minimize KL divergence since it is directly depend on posterior &lt;script type=&quot;math/tex&quot;&gt;p(z\mid x)&lt;/script&gt;. However we can minimize a function that is equal to KL divergence plus constant. This function is called &lt;strong&gt;Evidence Lower Bound&lt;/strong&gt;(ELBO) &lt;script type=&quot;math/tex&quot;&gt;\mathcal{L}_{VI}(q)&lt;/script&gt;.&lt;/p&gt;

&lt;h3 id=&quot;21-evidence-lower-bound-elbo&quot;&gt;2.1 Evidence Lower Bound (ELBO)&lt;/h3&gt;

&lt;p&gt;To derive the ELBO we first consider the &lt;a href=&quot;https://en.wikipedia.org/wiki/Jensen%27s_inequality&quot;&gt;Jensen’s inequality&lt;/a&gt; which relates the value of a convex function of an integral to the integral of the convex function such that &lt;script type=&quot;math/tex&quot;&gt;f(\mathbb{E}[x]) \geq \mathbb{E}[f(x)]&lt;/script&gt; where &lt;script type=&quot;math/tex&quot;&gt;f(.)&lt;/script&gt; is the concave function. Since logarithmic are strictly concave function it is clear that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\log \int p(x)g(x) dx \geq \int p(x)\log g(x)&lt;/script&gt;

&lt;p&gt;Let us consider a log of marginal evidence.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned} 
\log p(x) &amp; = \log \int_z p(x,z) dz\\
          &amp; =\log \int_z p(x,z)\cdot \frac{q(z)}{q(z)} dz \\
          &amp; =\log \int_z q(z)\frac{p(x,z)}{q(z)} dz\\
          &amp; =\log \left(\mathbb{E}_q[\frac{p(x,z)}{q(z)}] \right)\\
          &amp;\geq \mathbb{E}_q[ \log p(x,z)] - \mathbb{E}_q[\log q(z)]
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;The final line is the ELBO which is the lower bound for the evidence. Thus the evidence lower bound for probability model &lt;script type=&quot;math/tex&quot;&gt;p(x,z)&lt;/script&gt; and approximation &lt;script type=&quot;math/tex&quot;&gt;q(z)&lt;/script&gt; to the posterior is&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{L}_{VI}(q) = \mathbb{E}_q[ \log p(x,z)] - \mathbb{E}_q[\log q(z)]&lt;/script&gt;

&lt;p&gt;We can now show that KL divergence to the posterior is equal to the negative ELBO plus constant.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned} 
D_{KL}(q(z)||p(z|x)) &amp;= \int q(z)\log \frac{q(z)}{p(z|x)}\\
                     &amp;= \mathbb{E}_q[\log q(z)] - \mathbb{E}_q[\log p(x,z)] + \mathbb{E}_q[\log p(x)]\\
                     &amp;=-\left(\mathbb{E}_q[\log p(x,z)] - \mathbb{E}_q[\log q(z)] \right) +\log p(x)\\
                     &amp;= -\mathcal{L}_{VI}(q) +\log p(x)\\
\mathcal{L}_{VI}(q) &amp;=\log p(x) + D_{KL}(q(z)||p(z|x))
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;From the equation above it clear that minimizing the KL divergence is equivalent to maximizing the ELBO. Recall that we want to find &lt;script type=&quot;math/tex&quot;&gt;q(z)&lt;/script&gt; such that KL divergence is small, the variational objective function becomes&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;q^*(z) = \arg \min D_{KL}(q(z)||p(z|x)) = \arg \max \mathcal{L}_{VI}(q)&lt;/script&gt;

&lt;h3 id=&quot;3-mean-field-variational-inference&quot;&gt;3 Mean Field Variational Inference&lt;/h3&gt;

&lt;p&gt;One of the important question on VI, is how to construct the family of variational distributions from which we want to draw &lt;script type=&quot;math/tex&quot;&gt;q(z)&lt;/script&gt; from. The simplest family is where each latent parameter &lt;script type=&quot;math/tex&quot;&gt;z_i&lt;/script&gt; has its own
independent distribution. This means that we can easily factorize the variational distributions into groups:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;q(z_1, \ldots, z_m) = \prod_{i=1}^m q(z_i)&lt;/script&gt;

&lt;p&gt;This family of distribuion are known as Mean-Field Variational Family that make use of &lt;a href=&quot;https://en.wikipedia.org/wiki/Mean_field_theory&quot;&gt;mean field theory&lt;/a&gt;. Inference using this factorization is known as Mean-Field Variational Inference (MFVI).&lt;/p&gt;

&lt;p&gt;It possible to further parameterize the approximating distributions &lt;script type=&quot;math/tex&quot;&gt;q(z)&lt;/script&gt; with variational parameters &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt; such that the approximating distribution become &lt;script type=&quot;math/tex&quot;&gt;q(z_i ; \lambda_i)&lt;/script&gt;. For example if we set our family of approximating distributions as a set of
independent gauasian distributions &lt;script type=&quot;math/tex&quot;&gt;\mathcal{N}(\mu_i, \sigma^2_i)&lt;/script&gt; and parameterize this distributions with the mean and variance where &lt;script type=&quot;math/tex&quot;&gt;\lambda_i = (\mu_i, \sigma^2_i)&lt;/script&gt; is the set of variational parameters.&lt;/p&gt;

&lt;p&gt;The common algorithms used in practise to do VI under mean filed assumptions are coordinate ascent optimization (CAVI) and stochastic gradient based method.&lt;/p&gt;

&lt;h3 id=&quot;31-coordinate-ascent-variational-inference-cavi&quot;&gt;3.1 Coordinate Ascent Variational Inference (CAVI)&lt;/h3&gt;

&lt;p&gt;The CAVI algorithm derive variational updates by hand and perform coordinate ascent (iteratively updating each latent variable &lt;script type=&quot;math/tex&quot;&gt;z_i&lt;/script&gt; ) on the latent until convergence of the ELBO. A common procedure to conduct CAVI is:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Choose variational distributions &lt;script type=&quot;math/tex&quot;&gt;q(z)&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;Compute ELBO;&lt;/li&gt;
  &lt;li&gt;Optimize individual &lt;script type=&quot;math/tex&quot;&gt;q(z_i)&lt;/script&gt; ’s by taking the gradient for each latent variable;&lt;/li&gt;
  &lt;li&gt;Repeat until ELBO converges.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The coordinate ascent update for a latent variable can be derived by maximizing the ELBO function above. First, recall ELBO&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{L}_{VI}(q) = \mathbb{E}_q[ \log p(x,z)] - \mathbb{E}_q[\log q(z)]&lt;/script&gt;

&lt;p&gt;Using chain rule we can decomopse the joint  &lt;script type=&quot;math/tex&quot;&gt;p(x,z)&lt;/script&gt; as;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(x_{1:n}, z_{1:m}) = p(x_{1:n}) \prod_{i=1}^m p(z_i|z_{1:(i-1)}, x_{1:n})&lt;/script&gt;

&lt;p&gt;Using mean field approximation, we can decompose the entropy term of the ELBO as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbb{E}_q[\log q(z)] = \sum_{i=1}^m \mathbb{E}_q[\log q(z_i)]&lt;/script&gt;

&lt;p&gt;Under the above assumption the ELBO become:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{L}_{ELBO}(q) = \log p(x_{1:n}) + \sum_{i=1}^m \mathbb{E}_q[\log p(z_i|z_{1:(i-1)}, x_{1:n}) ] - \mathbb{E}_q[\log q(z_i)&lt;/script&gt;

&lt;p&gt;To find this &lt;script type=&quot;math/tex&quot;&gt;\arg \max_{q(z_i)} \mathcal{L}_{ELBO}(q)&lt;/script&gt; we take derivative of ELBO with respect to &lt;script type=&quot;math/tex&quot;&gt;q(z_i)&lt;/script&gt; using Lagrange multipliers and set the derivative to zero. It can be shown that the coordinate ascent update rule is equal to&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;q^*(z_i) \propto \{  \mathbb{E}_{q-i}[\log q(z_i,z_{\neg},x)]\}&lt;/script&gt;

&lt;p&gt;where the notation &lt;script type=&quot;math/tex&quot;&gt;\neg&lt;/script&gt; denotes all indices other than the &lt;script type=&quot;math/tex&quot;&gt;i^{th}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Despite being very fast  method for some models  only  work with  conditionally conjugate models.&lt;/p&gt;

&lt;h3 id=&quot;reference&quot;&gt;Reference&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.tamarabroderick.com/tutorial_2018_icml.html&quot;&gt;ICML 2018 tutorial&lt;/a&gt;:Variational Bayes and Beyond: Bayesian Inference for Big Data.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.shakirm.com/papers/VITutorial.pdf&quot;&gt;Shakir Mohamed&lt;/a&gt;:Variational Inference  for Machine Learning.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://emtiyaz.github.io/teaching/ds3_2018/ds3.html&quot;&gt;DS3 workshop&lt;/a&gt;:Approximate Bayesian Inference: Old and New.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/philschulz/VITutorial&quot;&gt;Variational Inference and Deep Generative Models&lt;/a&gt;:Variational Inference for NLP audiences&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Anthony Faustine</name></author><summary type="html">1. Introduction</summary></entry><entry><title type="html">Basics of Probability and Information Theory</title><link href="http://localhost:4000/ml/deep%20learning/probability/2018/06/08/deepprobabilistic_1.html" rel="alternate" type="text/html" title="Basics of Probability and Information Theory" /><published>2018-06-08T17:12:00+02:00</published><updated>2018-07-02T13:03:55+02:00</updated><id>http://localhost:4000/ml/deep%20learning/probability/2018/06/08/deepprobabilistic_1</id><content type="html" xml:base="http://localhost:4000/ml/deep%20learning/probability/2018/06/08/deepprobabilistic_1.html">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Probability and Information theory are important field that has made significant contribution to deep learning and AI. Probability theory allows us to make &lt;em&gt;uncertain statements&lt;/em&gt; and to &lt;em&gt;reason&lt;/em&gt; in the presence of &lt;em&gt;uncertainty&lt;/em&gt; where information theory enables us to &lt;em&gt;quantify&lt;/em&gt; the amount of &lt;em&gt;uncertainty&lt;/em&gt; in a probability distribution.&lt;/p&gt;

&lt;h2 id=&quot;1-probability-theory&quot;&gt;1. Probability Theory&lt;/h2&gt;

&lt;p&gt;Probability is a mathematical framework for representing uncertainty. It is very applicable in Machine learning and Artificial Intelligence as it allows to make &lt;em&gt;uncertain statements&lt;/em&gt; and  &lt;em&gt;reason&lt;/em&gt; in the presence of &lt;em&gt;uncertainty&lt;/em&gt;. Probability theory allow us to design ML algorithms that take into consideration  of &lt;em&gt;uncertain&lt;/em&gt; and sometimes &lt;em&gt;stochastic&lt;/em&gt;  quantities. It further tell us tell us how ML systems should &lt;em&gt;reason&lt;/em&gt; in the presence of uncertainty. This  is necessary because most things in the world  are uncertain, and thus  ML systems should reason using probabilistic rules. Probability theory can also be used to analyse the behaviour of  ML algorithms probabilistically. Consider evaluating ML classification algorithm using  accuracy metric which is  the probability that the model will give a correct prediction  given an example.&lt;/p&gt;

&lt;h3 id=&quot;12-random-experiment-sample-space-and-random-variable&quot;&gt;1.2 Random Experiment, Sample Space and Random Variable&lt;/h3&gt;
&lt;p&gt;Random experiment is the physical situation whose outcome cannot be predicted until it is observed. It is the process of observing event having uncertain outcome. When we repeat random experiment several times we call each of experiment a &lt;em&gt;trial&lt;/em&gt; The set of all possible outcomes of random experiment is know as &lt;em&gt;*sample space&lt;/em&gt; &lt;script type=&quot;math/tex&quot;&gt;S&lt;/script&gt;. Consider observing the number of goals in the soccer match as a random process. The sample space is the possible number of goals &lt;script type=&quot;math/tex&quot;&gt;S = \{0,1,\ldots n\}&lt;/script&gt;. For coin tossing experiment the sample space is &lt;script type=&quot;math/tex&quot;&gt;S = \{\text{Head, Tail}\}&lt;/script&gt; and for handwritten digit recognition experiment the sample space is &lt;script type=&quot;math/tex&quot;&gt;S = \{0,1,\ldots 9\}&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;A measurable function &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; which maps every member of the sample space &lt;script type=&quot;math/tex&quot;&gt;S&lt;/script&gt; to a real-number is called &lt;strong&gt;random variable&lt;/strong&gt;. Random variables can be continuous or discrete. Discrete random variable take only countable number of distinct values for  example populations, movie ratings and number of votes. On the other hand continuous random variable take infinite number of possible values. Things like temperature, speed, time etc are all modelled as continuous variables.&lt;/p&gt;

&lt;h3 id=&quot;13-probability-and-probability-distribution&quot;&gt;1.3 Probability and Probability distribution&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Probability&lt;/strong&gt; is a measure of the likelihood that an event will occur in a random experiment. It is quantified as number between 0 and 1. The mathematical function that maps all possible outcome of a random experiment with its associated probability it is called &lt;strong&gt;probability distribution&lt;/strong&gt;. It describe how likely a random variable or set of random variable is to take on each of its possible state. The probability distribution for discrete random variable is called probability mass function (PMF) which measures the probability &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; takes on the value &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;, denoted denoted as &lt;script type=&quot;math/tex&quot;&gt;P(X=x)&lt;/script&gt;.
To be PMF on random variable &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt;  a function &lt;script type=&quot;math/tex&quot;&gt;P(X)&lt;/script&gt; must satisfy:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Domain of &lt;script type=&quot;math/tex&quot;&gt;P&lt;/script&gt; equal to all possible states of &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;
    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\forall x \in X, 0\leq P(X=x) \leq 1&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\sum_{x \in X} P(x) =1&lt;/script&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Popular and useful PMF includes poison, binomial, bernouli, and uniform. Let consider a poison  distribution defined as:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(X=x) = \frac{\lambda ^x e^{ -\lambda}}{x!}&lt;/script&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\lambda &gt;0&lt;/script&gt; is called a parameter of the distribution, and it controls the distribution’s shape. By increasing &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt; , we add more probability to larger values, and conversely by decreasing &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt;  we add more probability to smaller values as shown in figure below.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;/assets/img/post/pmf.png&quot; title=&quot;PMF of a Poisson random variable&quot; alt=&quot;&quot; /&gt;
  &lt;figcaption&gt;PMF of a Poisson random variable
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Instead of a PMF, a continuous random variable has a probability density function (pdf) denoted as &lt;script type=&quot;math/tex&quot;&gt;f_X(x)&lt;/script&gt;. An example of continuous random variable is a random variable with exponential density.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f_X(x\mid \lambda) = \lambda ^x e^{ -\lambda} \text{,  } x \geq 0&lt;/script&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/img/post/pdf.png&quot; title=&quot;pdf of a exponential random variable&quot; alt=&quot;&quot; /&gt;
  &lt;figcaption&gt;pdf of a exponential random variable
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;To be a probability density function &lt;script type=&quot;math/tex&quot;&gt;p(x)&lt;/script&gt; must satisfy&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The domain of &lt;script type=&quot;math/tex&quot;&gt;p&lt;/script&gt; must be the set of all possible state&lt;/li&gt;
  &lt;li&gt;
    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\forall x \in X, f_X(x) \geq 0&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\int_{x \in X} f_X(x)dx =1&lt;/script&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The pdf does not give the probability of a specific state directly. The probability that &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; is between two point &lt;script type=&quot;math/tex&quot;&gt;a, b&lt;/script&gt; is&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\int_{a}^b f_X(x)dx&lt;/script&gt;

&lt;p&gt;The probability of intersection of two or more random variables is called &lt;em&gt;joint probability&lt;/em&gt; denoted  as &lt;script type=&quot;math/tex&quot;&gt;P(X, Y)&lt;/script&gt;
Suppose we have two random variable &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; and we know the joint PMF or pdf distribution between these variable. The PMF or pdf  corresponding to a single variable is called &lt;em&gt;marginal probability distribution&lt;/em&gt; defined as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(x) = \sum_{y\in Y} P(x, y)&lt;/script&gt;

&lt;p&gt;for discrete random variable and&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(x) = \int p(x)dy&lt;/script&gt;

&lt;p&gt;Marginalization allows us to get the distribution of variable &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; ignoring variable &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; from the joint distribution &lt;script type=&quot;math/tex&quot;&gt;P(X,Y)&lt;/script&gt;. The probability that some event will occur given we know other events is called condition probability denoted as &lt;script type=&quot;math/tex&quot;&gt;P(X\mid Y)&lt;/script&gt;. The  marginal, joint and conditional probability are linked by the following rule&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(X|Y) = \frac{P(X, Y)}{P(Y)}&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Independence, Conditional Independence and Chain Rule&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Two random variables are said to be independent of each other if the probability that one random variables occur in no way affect the probability of the other random variable occurring. &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; are said to be independent if &lt;script type=&quot;math/tex&quot;&gt;P(X,Y) = P(X)\cdot P(Y)&lt;/script&gt;
On the other hand two random variable &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; are conditionally independent given an event &lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; with &lt;script type=&quot;math/tex&quot;&gt;P(Z)&gt;0&lt;/script&gt; if&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;P(X,Y\mid Z) = P(X\mid Y)\cdot P(Y\mid Z)&lt;/script&gt;
The good example of conditional independence can be found on this &lt;a href=&quot;&quot;&gt;link&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Any joint probability distribution over many random variables may be decomposed into conditional distributions using &lt;em&gt;chain rule&lt;/em&gt; as follows:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(X_1,X_2, \ldots, X_n ) = P(X_1)\prod_{i=2}^n P(X_i\mid X_i, \ldots X_{i-1})&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Expectation, Variance and Covariance&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Expected value of some function &lt;script type=&quot;math/tex&quot;&gt;f(x)&lt;/script&gt; with respect to a probability distribution &lt;script type=&quot;math/tex&quot;&gt;P(X)&lt;/script&gt; is the average or mean value that &lt;script type=&quot;math/tex&quot;&gt;f(x)&lt;/script&gt; takes on when &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; is drawn from &lt;script type=&quot;math/tex&quot;&gt;P&lt;/script&gt;.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbb{E}_{x\sim P}[f(x)] = \sum P(x).f(x)&lt;/script&gt;

&lt;p&gt;for discrete random variable and&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbb{E}_{x\sim P}[f(x)] = \int P(x).f(x)dx&lt;/script&gt;

&lt;p&gt;Expectation are linear such that 
&lt;script type=&quot;math/tex&quot;&gt;\mathbb{E}_{x\sim P}[\alpha \cdot f(x) + \beta \cdot g(x)] = \alpha \mathbb{E}_{x\sim P}[f(x)] + \beta \mathbb{E}_{x\sim P}[g(x)]&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Variance is a measure of how much the value of a function of random variable &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; vary as we sample different value of &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; from its probability distribution.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Var(f(x)) =\mathbb{E}([f(x)-\mathbb{E}[f(x)]^2])&lt;/script&gt;

&lt;p&gt;The square root of the variance is know as standard deviation. On the other hand the covarince give some sense of how much two value are linearly related to each other as well as the scale of these value.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Cov(f(x), g(y)) = \mathbb{E}[(f(x)- \mathbb{E}[f(x)])(g(y)- \mathbb{E}[g(y)])]&lt;/script&gt;

&lt;h3 id=&quot;2-information-theory&quot;&gt;2. Information theory&lt;/h3&gt;
&lt;p&gt;Information theory deals with quantification of how much information is present in a signal. In context of machine learning, information theory we apply information theory to: &lt;em&gt;characterize probability distributions&lt;/em&gt; and &lt;em&gt;quantify similarities between probability distributions&lt;/em&gt;. The following are the key information concepts and their application to machine learning.&lt;/p&gt;

&lt;h3 id=&quot;21-entropy-cross-entropy-and-mutual-information&quot;&gt;2.1 Entropy, Cross Entropy and Mutual information&lt;/h3&gt;

&lt;p&gt;Entropy give measure of uncertainty in a random experiment. It help us  quantify the amount of uncertainty in an entire probability distribution. The entropy of a probability distribution is the expected amount of information in an event drawn from that distribution defined as.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;H(X) = -\mathbb{E}_{x \sim P}[\log P(x)] = -\sum_{i=1}^n P(x_i)l\log P(x_i)&lt;/script&gt;

&lt;p&gt;Entropy is widely used in model selection based on principle of maximum entropy. On the other hand, cross entropy is used to compare two probability distribution. It tell how similar two distribution are. The cross entropy between two probability distribution &lt;script type=&quot;math/tex&quot;&gt;P&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;Q&lt;/script&gt; defined over same set of outcome is given by&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;H(P,Q)= -\sum P(x)\log Q(x)&lt;/script&gt;

&lt;p&gt;Cross entropy loss function is widely used in machine learning for classification problem.&lt;/p&gt;

&lt;p&gt;The mutual information over two random variables help us gain insight about the information that one random variable carries about the other.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
I(X, Y) &amp;= \sum P(x, y)\log \frac{P(x,y)}{P(x).P(y)}\\
        &amp;=H(X)- H(X\mid Y) = H(Y) - H(Y\mid X)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;From above equation the mutual information  give insight about how far &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; from being independent from each other. Mutual information can be used in feature selection instead of correlation as it capture both linear and non linear dependency.&lt;/p&gt;

&lt;h3 id=&quot;22-kullback-leibler-divergence&quot;&gt;2.2 Kullback-leibler Divergence&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Kullback-leibler Divergence&lt;/strong&gt; measure how one probability distribution diverge from the other. Given two probability distribution &lt;script type=&quot;math/tex&quot;&gt;P(x)&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;Q(X)&lt;/script&gt; where the former is the modelled/estimated distribution and the later is the actual/expected distribution. The &lt;strong&gt;KL&lt;/strong&gt; divergence is defined as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
D_{KL}(P||Q) &amp; = \mathbb{E}_{x \sim P} [\log \frac{P(x)}{Q(x)}]\\
             &amp; = \mathbb{E}_{x \sim P}[\log P(x)] - \mathbb{E}_{x \sim P}[\log Q(x)]
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;For discrete random distribution&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;D_{KL}(P||Q) = \sum_{i} P(x_i)\log \frac{P(x_i)}{Q(x_i)}&lt;/script&gt;

&lt;p&gt;And for continuous random variable&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;D_{KL}(p||q) = \int_{x} p(x) \log \frac{p(x)}{q(x)}&lt;/script&gt;

&lt;p&gt;KL divergence between &lt;script type=&quot;math/tex&quot;&gt;P&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;Q&lt;/script&gt; tells how much information we lose when trying to approximate data given by &lt;script type=&quot;math/tex&quot;&gt;P&lt;/script&gt; with &lt;script type=&quot;math/tex&quot;&gt;Q&lt;/script&gt;. It is non-negative &lt;script type=&quot;math/tex&quot;&gt;D_{KL}(P\mid \mid Q) \geq 0&lt;/script&gt; and  &lt;script type=&quot;math/tex&quot;&gt;0&lt;/script&gt; if &lt;script type=&quot;math/tex&quot;&gt;P&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;Q&lt;/script&gt; are the same (distribution discrete) or equal almost anywhere in the case of continuous distribution. Apart from that KL divergence is not symmetric &lt;script type=&quot;math/tex&quot;&gt;D_{KL}(P\mid \mid Q) \neq D_{KL}(P\mid \mid Q)&lt;/script&gt; because of this it is not a true distance measure.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Relation between KL divergence and Cross Entropy&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
D_{KL}(P||Q) &amp; = \mathbb{E}_{x \sim P} [\log \frac{P(x)}{Q(x)}]\\
             &amp; = \mathbb{E}_{x \sim P}[\log P(x)] - \mathbb{E}_{x \sim P}[\log Q(x)]\\
             &amp; = H(P) - H(P, Q)\\
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;\mathbb{E}_{x \sim P}[\log P(x)] = H(P)&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\mathbb{E}_{x \sim P}[\log Q(x)] = H(P, Q)&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Thus&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;H(P,Q) = H(P) - D_{KL}(P||Q)&lt;/script&gt;

&lt;p&gt;This implies that minimizing cross entropy with respect to &lt;script type=&quot;math/tex&quot;&gt;Q&lt;/script&gt; is equivalent to minimizing the KL divergence.&lt;/p&gt;

&lt;p&gt;KL divergence is used in unsupervised machine learning technique like variational auto-encoder. The KL divergence is also used  as objective function in variational bayesian method to find optimal value for approximating distribution.&lt;/p&gt;</content><author><name>Anthony Faustine</name></author><summary type="html">Introduction</summary></entry><entry><title type="html">Learning HMM parameters for Continous Density Models</title><link href="http://localhost:4000/ml/hmm/2017/06/12/hmm-gausian.html" rel="alternate" type="text/html" title="Learning HMM parameters for Continous Density Models" /><published>2017-06-12T17:12:00+02:00</published><updated>2017-10-01T19:21:51+02:00</updated><id>http://localhost:4000/ml/hmm/2017/06/12/hmm-gausian</id><content type="html" xml:base="http://localhost:4000/ml/hmm/2017/06/12/hmm-gausian.html">&lt;p&gt;In the previous post we considered a scenario in which observation sequences &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; are discrete symbols. However, for many practical problems the observation symbols are continous vectors. As the results the contious probability desnsity function (pdfs) are used to model the space of the observation signal associated with each state. Most commonly used emission distribution are gaussian distribution and the gausian mixture models.&lt;/p&gt;

&lt;h3 id=&quot;gaussian-distribution-and-the-gausian-mixture-models&quot;&gt;Gaussian Distribution and the Gausian Mixture Models&lt;/h3&gt;

&lt;p&gt;It is popular to represent the randomness of continuous-valued  using the multivariate Gaussian distribution. A vector-valued random variable &lt;script type=&quot;math/tex&quot;&gt;\mathbf{x}&lt;/script&gt; is said to have a multivariate normal (or Gaussian) distribution with mean &lt;script type=&quot;math/tex&quot;&gt;\mu=\mathop{\mathbf{E[x]}}&lt;/script&gt; and covariance matrix &lt;script type=&quot;math/tex&quot;&gt;\Sigma=\mathbf{cov[x]}&lt;/script&gt; if:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(\mathbf{x}; \mu, \Sigma) = \mathcal{N(\mathbf{x} \mid \mu, \Sigma)}=\frac{1}{(2\pi)^{D/2} |\Sigma|^\frac{1}{2}}\quad\exp\Big(-\frac{1}{2}[\mathbf{x} - \mu] \Sigma^{-1}[\mathbf{x} - \mu]^\mathsf{T} \Big)&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;D&lt;/script&gt; is the dimensionality of &lt;script type=&quot;math/tex&quot;&gt;\mathbf{x}&lt;/script&gt;. The &lt;script type=&quot;math/tex&quot;&gt;\mu&lt;/script&gt; represents the location where samples are most likely to be generated and the &lt;script type=&quot;math/tex&quot;&gt;\Sigma&lt;/script&gt; indicates the level to which two variables vary together.&lt;/p&gt;

&lt;p&gt;However, a single Gaussian distribution is insufficient to represent the state-dependent observation space for an HMM state &lt;script type=&quot;math/tex&quot;&gt;s_t=i&lt;/script&gt; because there are large amounts of training data collected from various appliance instances with different modes, distortions, background noises, etc which are used to train the parameters of individual HMM states. In this case, a Gaussian mixture model (GMM) is adopted to represent the state-dependent observation space.&lt;/p&gt;

&lt;p&gt;A mixture model is a probabilistic model for density estimation using a mixture distribution and can be regarded as a type of unsupervised learning or clustering. They provide a method of describing more complex propability distributions, by combining several probability distributions. A multivariate Gaussian mixture distribution is given by the following equation:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(\mathbf{x}) = \displaystyle\sum_{k=1}^{K}\omega_k \mathcal{N(\mathbf{x} \mid \mu_k, \Sigma_k)}&lt;/script&gt;

&lt;p&gt;The parameters &lt;script type=&quot;math/tex&quot;&gt;\omega_k&lt;/script&gt; are called mixing coefficients, which must fulfill&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\displaystyle\sum_{k=1}^{K}\omega_k =1&lt;/script&gt;

&lt;p&gt;and given &lt;script type=&quot;math/tex&quot;&gt;\mathcal{N(\mathbf{x} \mid \mu_k, \Sigma_k)} \geq 0&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;P(\mathbf{x}) \geq 0&lt;/script&gt; we also have that 
&lt;script type=&quot;math/tex&quot;&gt;0\leq \omega_k \geq 1&lt;/script&gt;. Each Gaussian density &lt;script type=&quot;math/tex&quot;&gt;\mathcal{N(\mathbf{x} \mid \mu_k, \Sigma_k)}&lt;/script&gt; is
called a component of the mixture and has its own mean &lt;script type=&quot;math/tex&quot;&gt;\mu_k&lt;/script&gt;   and covariance &lt;script type=&quot;math/tex&quot;&gt;\Sigma_k&lt;/script&gt;.&lt;/p&gt;

&lt;h3 id=&quot;hmm-with-gaussian-emission-distribution&quot;&gt;HMM with gaussian emission distribution&lt;/h3&gt;

&lt;p&gt;If the observations are continuous, it is common for the emission probabilities to be a conditional
Gaussian such that:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(\mathbb{y_t} \mid s_t =i) = \mathcal{N(\mathbf{y_t} \mid \mu_i, \Sigma_i)}&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;\mu_i&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\Sigma_i&lt;/script&gt; are mean vector and covariance matrix associated with state &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;The re-estimation formula for the mean vector and covariance matrix of a state gausian pdf can be derived as:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
 \hat{\mu}_i &amp; =\frac{\displaystyle\sum_{t=1}^{T}\gamma_t(i)\mathbb{y(t)}}{\displaystyle\sum_{t=1}^{T}\gamma _t(i)}\\
 \hat{\Sigma}_i &amp; =\frac{\displaystyle\sum_{t=1}^{T}\gamma_t(i) [\mathbf{y(t)}-\hat{\mu}_i]\cdot[\mathbf{y(t)}-\hat{\mu}_i]^T}{\displaystyle\sum_{t=1}^{T}\gamma_t(i)}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;h3 id=&quot;hmms-with-gaussian-mixture-model&quot;&gt;HMMs with Gaussian Mixture Model&lt;/h3&gt;

&lt;p&gt;In HMMs with gaussian mixture pdf, the emission probabilities is given by&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;P(\mathbb{y_t} \mid s_t =i) = \displaystyle\sum_{k=1}^{M} \omega\_{ik}\mathcal{N(\mathbb{y_t} \mid \mu_{ik}, \Sigma_{ik})}&lt;/script&gt;
  where &lt;script type=&quot;math/tex&quot;&gt;\omega_{ik}&lt;/script&gt; is the prior probability of the  &lt;script type=&quot;math/tex&quot;&gt;k^{th}&lt;/script&gt; component of the mixture.&lt;/p&gt;

&lt;p&gt;The posterior probability of state &lt;script type=&quot;math/tex&quot;&gt;s_t=i&lt;/script&gt; at time &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt; and state &lt;script type=&quot;math/tex&quot;&gt;s_{t+1}=j&lt;/script&gt; at time &lt;script type=&quot;math/tex&quot;&gt;t+1&lt;/script&gt; given the model &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt; and the observation sequence &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; is&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
 \gamma_t(i,j)&amp; =P(s_t=i, s_{t+1}=j \mid Y, \lambda) \\
 &amp; = \frac{\alpha_t(i)a_{ij}\Big[ \displaystyle\sum_{k=1}^{M} \omega_{ik}\mathcal{N(\mathbf{y_t} \mid \mu_{ik}, \Sigma_{ik})} \Big]\beta_{t+1}(j)}{\displaystyle\sum_{i=1}^{N}\alpha_T(i)}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;and the posterior probability of state &lt;script type=&quot;math/tex&quot;&gt;s_t=i&lt;/script&gt; at time &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt; given the model &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt; and observation &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; is&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\gamma_t(i) =\frac{\alpha_t(i)\beta_t(i)}{\displaystyle\sum_{i=1}^{N}\alpha _T(i)}&lt;/script&gt;

&lt;p&gt;Let define the joint posterior probability of the state &lt;script type=&quot;math/tex&quot;&gt;s_i&lt;/script&gt; and the &lt;script type=&quot;math/tex&quot;&gt;k^{th}&lt;/script&gt; gaussian component pdf of state &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; at time &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\xi(i,k) &amp;= P(S_t=s_i, m(t)=k \mid Y, \lambda) \\
 &amp;=\frac{\displaystyle\sum_{j=1}^{N} \alpha_t(j) a_{ij} \omega_{ik}\mathcal{N(\mathbf{y_t} \mid \mu_{ik}, \Sigma_{ik})}\beta_{t+1}(j)}{\displaystyle\sum_{i=1}^{N}\alpha _T(i)} 
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;The re-estimation formula for the mixture coefficeints, the mean vectors and the covariance matrices of the state mixture gausian pdf as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
 \hat{\omega}_{ik} &amp;= \frac{\displaystyle \sum_{t=1}^{T} \xi_t(i,k)}{\displaystyle\sum\_{t=0}^{T}\gamma_t(i)} \\
\hat{\mu}_{ik} &amp;= \frac{\displaystyle\sum\ _{t=1}^{T}\xi\ _t(i,k)\mathbf{y_t}}{\displaystyle\sum_{t=1}^{T}\xi_t(i,k)} \\
\hat{\Sigma}_{ik}&amp;=\frac{\displaystyle\sum_{t=1}^{T}\xi_t(i,k)[\mathbf{y_t}-\hat{\mu}_{ik}]\cdot[\mathbf{y_t}-\hat{\mu}_{ik}]^T}{\displaystyle\sum_{t=1}^{T}\xi_t(i,k)}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;h3 id=&quot;limitation-of-baumwelch-algorithm&quot;&gt;Limitation of Baum–Welch algorithm&lt;/h3&gt;

&lt;p&gt;When applying Baum–Welch algorithm  in real  data, we need to consider some heuristics in the ML EM algorithm.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;How to provide initial parameters values. This is always an important question, and it is usually resolved by using a simple algorithm (e.g., K-means clustering or random initialization).&lt;/li&gt;
  &lt;li&gt;How to avoid unstability in the parameter estimation (especially covariance parameter estimation) due to data sparseness. For examle some mixture components or hidden states cannot have sufficient data assigned in the Viterbi or forward–backward algorithm. This can be heuristically avoided by setting a threshold to update these parameters, or setting minimum threshold values for covariance parameters.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The above two problem can be solved by the Bayesian approaches.&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;Saeed V. Vaseghi, Advanced Digital Signal Processing and Noise Reduction. John Wiley &amp;amp; Sons, 2008.&lt;/li&gt;
  &lt;li&gt;Kevin P. Murphy, Machine Learning: A Probabilistic Perspective. The MIT Press Cambridge, Massachusetts, 2012.&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Anthony Faustine</name></author><summary type="html">In the previous post we considered a scenario in which observation sequences are discrete symbols. However, for many practical problems the observation symbols are continous vectors. As the results the contious probability desnsity function (pdfs) are used to model the space of the observation signal associated with each state. Most commonly used emission distribution are gaussian distribution and the gausian mixture models.</summary></entry><entry><title type="html">Learning HMM parameters with Discrete Observation Models</title><link href="http://localhost:4000/ml/hmm/2017/05/29/hmm-discrete.html" rel="alternate" type="text/html" title="Learning HMM parameters with Discrete Observation Models" /><published>2017-05-29T17:12:00+02:00</published><updated>2017-10-01T19:21:51+02:00</updated><id>http://localhost:4000/ml/hmm/2017/05/29/hmm-discrete</id><content type="html" xml:base="http://localhost:4000/ml/hmm/2017/05/29/hmm-discrete.html">&lt;p&gt;In Previous post we discussed the basic of HMM modeling given model parameters &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt; and  compute the likelihood values etc, efficiently based on the forward, backward, and Viterbi algorithms. In the like manner, we can efficiently train the HMM to obtain the model parameter &lt;script type=&quot;math/tex&quot;&gt;\hat{\lambda}&lt;/script&gt; from data. In this post we will discuss different methods for training HMM models.&lt;/p&gt;

&lt;p&gt;This is the solution to Problem 3 which involve determining a method to learn model parameters &lt;script type=&quot;math/tex&quot;&gt;\hat{\lambda}&lt;/script&gt; given the sequence of observation variables &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt;. Given the observation sequences &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; as training data, there is no optimal way of estimating the model parametrs. However, using iterative procedure we can choose &lt;script type=&quot;math/tex&quot;&gt;\hat{\lambda} = (\hat{A},\hat{B},\hat{\pi})&lt;/script&gt; such that &lt;script type=&quot;math/tex&quot;&gt;P(Y \mid \lambda)&lt;/script&gt; is locally maximized.The most common produre which has been employed to his problem is the &lt;strong&gt;Baum-Welch&lt;/strong&gt; method.&lt;/p&gt;

&lt;h3 id=&quot;baum-welch-methods&quot;&gt;Baum-Welch Methods&lt;/h3&gt;

&lt;p&gt;This method assume an initial model parameters &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt; which should be adjusted so as to increase &lt;script type=&quot;math/tex&quot;&gt;P(Y \mid \lambda)&lt;/script&gt;. The initial parametrs can be constructed in any way or employ the first five procedure of the &lt;a href=&quot;http://www.ece.ucsb.edu/Faculty/Rabiner/ece259/Reprints/segmental%20k-means%20algorithm.pdf&quot;&gt;Segmental K-means algorithm&lt;/a&gt;. The optimazation criteria is called the &lt;strong&gt;maximum likelihood criteria&lt;/strong&gt;.The function &lt;script type=&quot;math/tex&quot;&gt;P(Y \mid \lambda)&lt;/script&gt; is called the &lt;strong&gt;likelihood function&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;the-e-m-auxilliary-function&quot;&gt;The E-M Auxilliary Function&lt;/h3&gt;

&lt;p&gt;Let &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt; represent the current model and &lt;script type=&quot;math/tex&quot;&gt;\hat{\lambda}&lt;/script&gt; represent the candidate models. The learning objective is to make: &lt;script type=&quot;math/tex&quot;&gt;P(Y \mid \hat{\lambda}) \geq P(Y \mid \lambda)&lt;/script&gt; which is equivalently to &lt;script type=&quot;math/tex&quot;&gt;\log[P(Y \mid \hat{\lambda})] \geq \log [P(Y\mid \lambda)]&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Let also define the auxilliary function &lt;script type=&quot;math/tex&quot;&gt;Q(\hat{\lambda}\mid \lambda)&lt;/script&gt; such that:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
Q(\hat{\lambda}\mid \lambda) &amp; = \mathbb{E}\Big[\log P(Y,S \mid \hat{\lambda})\mid Y, \lambda \Big] \\
                            &amp; = \sum_s P(S \mid Y, \lambda)\cdot \log [P(Y,S\mid \hat{\lambda})]
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;The Maximum Likehood Estimation (MLE) of the model parameter &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt; for complete data &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; and hidden state &lt;script type=&quot;math/tex&quot;&gt;S&lt;/script&gt; is;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{\lambda} = \arg\max _{\lambda} \sum_s P(Y, S \mid \lambda)&lt;/script&gt;

&lt;p&gt;However due to the presence of several stochatsic constraints it turns out to be easier to mximize uxilliary function &lt;script type=&quot;math/tex&quot;&gt;Q(\hat{\lambda}\mid \lambda)&lt;/script&gt; rather than directly maximize &lt;script type=&quot;math/tex&quot;&gt;P(Y\mid \hat{\lambda})&lt;/script&gt;. Thus the MLE of the model parameter &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt; for complete data &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; and hidden state &lt;script type=&quot;math/tex&quot;&gt;S&lt;/script&gt; become:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{\lambda} = \arg\max _{\lambda} Q(\hat{\lambda}\mid\lambda)&lt;/script&gt;

&lt;p&gt;It can be shown that the parameter estimated by the EM procedure, &lt;script type=&quot;math/tex&quot;&gt;Q(\hat{\lambda}\mid \lambda)&lt;/script&gt;, always increases the likelihood value. You may concert &lt;a href=&quot;https://books.google.co.tz/books/about/Bayesian_Speech_and_Language_Processing.html?id=rEzzCQAAQBAJ&amp;amp;printsec=frontcover&amp;amp;source=kp_read_button&amp;amp;redir_esc=y#v=onepage&amp;amp;q&amp;amp;f=false&quot;&gt;reference 2&lt;/a&gt; chapter 3 for details on the prove.&lt;/p&gt;

&lt;h3 id=&quot;expectation-step&quot;&gt;Expectation step&lt;/h3&gt;

&lt;p&gt;To find ML estimates of HMM parameters, we first expand the auxiliary function rewrite it by substituting the joint distribution of complete data likelihood.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
Q(\hat{\lambda} \mid \lambda) &amp; = \mathbf{E}\Big[\log P(Y,S\mid\hat{\lambda})\mid Y, \lambda \Big] \\
&amp; = \sum_s P(S\mid Y, \lambda)\cdot \log [P(Y,S\mid\hat{\lambda})] \\
&amp; = \sum_s P(S\mid Y, \lambda)\cdot \Big[\log \hat{\pi}_1 + \log \hat{b}_1(y_1) + \sum _{t=2}^T\big( \log \hat{a} _{ij} + \log \hat{b}_i({y_t})\big)\Big] 
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;We have three term to solve:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The initial probability &lt;script type=&quot;math/tex&quot;&gt;\hat{\pi}&lt;/script&gt; ,&lt;/li&gt;
  &lt;li&gt;State transition probability &lt;script type=&quot;math/tex&quot;&gt;\hat{A} = \hat{a}_{ij}&lt;/script&gt; and&lt;/li&gt;
  &lt;li&gt;Emission probability &lt;script type=&quot;math/tex&quot;&gt;\hat{B} = \hat{b}_i(y_t)&lt;/script&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Let first define important parameters that we will use. For &lt;script type=&quot;math/tex&quot;&gt;t = 1,2...T&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;1\leq i \geq N&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;1\leq j \geq N&lt;/script&gt;, we define:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\xi_t(i,j)=P(s_t=i, s_{t+1}=j \mid Y, \lambda)&lt;/script&gt;

&lt;p&gt;an expected transition probability from &lt;script type=&quot;math/tex&quot;&gt;s_t=i&lt;/script&gt; to , &lt;script type=&quot;math/tex&quot;&gt;s_{t+1}=j&lt;/script&gt;. The probability of being in state &lt;script type=&quot;math/tex&quot;&gt;s_i&lt;/script&gt; at time &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt; and state &lt;script type=&quot;math/tex&quot;&gt;s_j&lt;/script&gt; at time &lt;script type=&quot;math/tex&quot;&gt;t+1&lt;/script&gt; given the model &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt; and observation sequences &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\xi_t(i,j)&lt;/script&gt; can be written in terms of forward &lt;script type=&quot;math/tex&quot;&gt;\alpha_t(i)&lt;/script&gt; and backward &lt;script type=&quot;math/tex&quot;&gt;\beta_{t+1}(j)&lt;/script&gt; variables as:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}   
\xi_t(i,j) &amp;= \frac{\alpha_t(i)a_{ij}b_i(y_{t+1})\beta_{t+1}(j)}{P(Y \mid \lambda)} \\ 
          &amp;= \frac{\alpha_t(i)a_{ij}b_i(y_{t+1})\beta_{t+1}(i)}{\displaystyle \sum_{i=1}^{N}\displaystyle \sum_{j=1}^{N}\alpha_t(i)a_{ij}b_j(y_{t+1})\beta_{t+1}(j)}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;where the numerator term is just &lt;script type=&quot;math/tex&quot;&gt;P(S_t=s_i, S_{t+1}=s_j \mid Y, \lambda)&lt;/script&gt;  and the division by &lt;script type=&quot;math/tex&quot;&gt;P(Y \mid \lambda)&lt;/script&gt; gives the desire probability measures.&lt;/p&gt;

&lt;p&gt;We have previosly difined &lt;script type=&quot;math/tex&quot;&gt;\gamma_t(i) =  \frac{\alpha_t(i)\beta_t(i)}{P(Y \mid \lambda)}&lt;/script&gt; as the probability of being in state &lt;script type=&quot;math/tex&quot;&gt;s_i&lt;/script&gt; at time &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt; given the observation sequence and model parameter. &lt;script type=&quot;math/tex&quot;&gt;\gamma_t(i)&lt;/script&gt; relate to &lt;script type=&quot;math/tex&quot;&gt;\xi_t(i,j)&lt;/script&gt; as follows:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\gamma_t(i) = \displaystyle\sum_{j=1}^{N}\xi_t(i,j)&lt;/script&gt;

&lt;p&gt;It follows that:&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\displaystyle\sum_{t=1}^{T-1}\gamma_t(i)=&lt;/script&gt; Expected number of transitions from state &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; .&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\displaystyle\sum_{t=1}^{T-1}\xi_t(i,j)=&lt;/script&gt; Expected number of transitions from state &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; to state &lt;script type=&quot;math/tex&quot;&gt;j&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;We provide the solution for each term. Considering the first term  &lt;script type=&quot;math/tex&quot;&gt;Q(\hat{\pi} \mid \pi)&lt;/script&gt; we define the following auxiliary function for &lt;script type=&quot;math/tex&quot;&gt;\pi _i&lt;/script&gt;  as:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Q(\hat{\pi}\mid \pi) = \sum_s P(S\mid Y, \lambda)\cdot \log \hat{\pi}_{s_1}&lt;/script&gt;

&lt;p&gt;Since &lt;script type=&quot;math/tex&quot;&gt;\hat{\pi}_{s_1}&lt;/script&gt; only depends on &lt;script type=&quot;math/tex&quot;&gt;s_1&lt;/script&gt;, it clear that:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(S\mid Y, \lambda) = P(s_1\mid Y, \lambda)&lt;/script&gt;

&lt;p&gt;Therefore &lt;script type=&quot;math/tex&quot;&gt;Q(\hat{\pi}\mid pi)&lt;/script&gt;  can be rewritten as:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
Q(\hat{\pi}\mid \pi) &amp;= \sum_{s_1}P(s_1 \mid Y, \lambda)\cdot \log \hat{\pi}_{s_1} \\
                     &amp;= \sum_{i=1}^N P(s_1=i \mid Y, \lambda)\cdot \log \hat{\pi}_{i} \\
                     &amp; = \sum_{i=1}^N \gamma_t(i) \log \hat{\pi}_{i}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;Next, we focus on the second term &lt;script type=&quot;math/tex&quot;&gt;Q(\hat{A}\mid A)&lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Q(\hat{A}\mid A) = \sum_s P(S\mid Y, \lambda) \cdot \sum _{t=2}^T  \log \hat{a}_{s_t,s_{t+1}}&lt;/script&gt;

&lt;p&gt;Similar to &lt;script type=&quot;math/tex&quot;&gt;Q(\hat{\pi}\mid \pi)&lt;/script&gt; , we obtain
&lt;script type=&quot;math/tex&quot;&gt;P(S\mid Y, \lambda) = P(s_1\mid Y, \lambda) = P(s_t,s_{t+1}\mid Y, \lambda)&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Therefore&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
Q(\hat{A}\mid A) &amp; =  \sum _{t=1}^{T-1}  \sum_s P(s_t,s_{t+1}\mid Y, \lambda) \log \hat{a}_{s_t,s_{t+1}} \\
 &amp; = \sum _{t=1}^{T-1} \sum_{i=1}^N \sum_{j=1}^N P(s_t=i,s_{t+1}=j\mid Y, \lambda) \log \hat{a}_{ij} \\
&amp; = \sum _{t=1}^{T-1} \sum_{i=1}^N \sum_{j=1}^N \xi_t(i,j) \log \hat{a}_{ij}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;Finally, we focus on the last term &lt;script type=&quot;math/tex&quot;&gt;Q(\hat{B}\mid B)&lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Q(\hat{B}\mid B) = \sum_s P(S\mid Y, \lambda)\cdot \sum _{t=1}^T  \log \hat{b}_{i}(y_t)&lt;/script&gt;

&lt;p&gt;Similary &lt;script type=&quot;math/tex&quot;&gt;P(S\mid Y, \lambda) = P(s_t = i\mid Y, \lambda)&lt;/script&gt;. Therefore&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
Q(\hat{B}\mid B) &amp;= \sum _{t=1}^T \sum_s P(s_t = i\mid Y, \lambda) \log \hat{b}_{i}(y_t) \\
&amp; = \sum _{t=1}^T \sum_{i=1}^N \gamma_t(i)\log \hat{b}_{i}(y_t)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;Thus, we summarize the auxiliary function&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Q(\hat{\lambda}\mid \lambda)= Q(\hat{\pi}\mid \pi)+ Q(\hat{A}\mid A) + Q(\hat{B}\mid B)&lt;/script&gt;

&lt;h3 id=&quot;maximization-step&quot;&gt;Maximization step&lt;/h3&gt;

&lt;p&gt;In the maximization step, we aim to maximize &lt;script type=&quot;math/tex&quot;&gt;Q(\hat{\pi} \mid \pi)&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;Q(\hat{A} \mid A)&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;Q(\hat{B} \mid B)&lt;/script&gt; with respect to &lt;script type=&quot;math/tex&quot;&gt;\hat{\pi}&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;\hat{A}&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\hat{B}&lt;/script&gt; under the following constraints.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sum\_{i=1}^N \hat{\pi} = 1, \text{ and } \sum_{i=1}^N \hat{A} = 1&lt;/script&gt;

&lt;p&gt;Considering the estimation of initial state probabilities &lt;script type=&quot;math/tex&quot;&gt;\mathbf{\hat{\pi}} = {\hat{\pi}_i}&lt;/script&gt; , we construct a Lagrange function (or Lagrangian):&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Q^*(\hat{\pi} \mid \pi) =\sum_{i=1}^N \gamma_1(i) \log \hat{\pi}_{i} + \eta \left(\sum_{i=1}^N \hat{\pi} - 1 \right)&lt;/script&gt;

&lt;p&gt;Differentiating this Lagrangian with respect to individual probability parameter &lt;script type=&quot;math/tex&quot;&gt;\hat{\pi}_i&lt;/script&gt;  and set it to zero we obtain.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\frac{\partial Q^*(\hat{\pi} \mid \pi)}{\partial \hat{\pi}_i } &amp; = \gamma_1(i) \frac{1}{\hat{\pi}_i} + \eta = 0 \\
\hat{\pi}_i &amp;=  - \frac{1}{\eta}\gamma_1(i)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;Substituting the above equation into &lt;script type=&quot;math/tex&quot;&gt;\sum_{i=1}^N \hat{\pi} = 1&lt;/script&gt; constraint, we obtain:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\sum_{i=1}^N \hat{\pi} &amp;= \sum_{i=1}^N - \frac{1}{\eta}\gamma_1(i) = 1 \\
\Rightarrow \eta &amp;= - \sum_{i=1}^N \gamma_1(i)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;The ML estimate of new initial state probability is obtained by substituting the above equation into &lt;script type=&quot;math/tex&quot;&gt;\hat{\pi}_i =  - \frac{1}{\eta}\gamma_1(i)&lt;/script&gt;:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{\pi}_i = \frac{\gamma_1(i)}{\sum _{i=1}^N \gamma_1(i)} = \gamma_1(i)&lt;/script&gt;

&lt;p&gt;In the same manner, we can derive the ML estimates of new state transition probability and new emission probability, which can be shown to be:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{a}_{ij} = \frac{\displaystyle \sum_{t=1}^{T-1}\xi_t(i,j)}{\displaystyle\sum_{t=1}^{T-1}\gamma_t(i)}&lt;/script&gt;

&lt;p&gt;And&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{b}_i(k) = \frac{\displaystyle\sum_{t=1}^{T}\tau \gamma_t(i)}{\displaystyle\sum_{t=1}^{T} \gamma_t(i)}&lt;/script&gt;

&lt;p&gt;where&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\tau =
 \begin{cases}
1 \text{ if } y_t = k, \\ 0  \text{ otherwise }
\end{cases}&lt;/script&gt;

&lt;p&gt;If we denote the initial model &lt;script type=&quot;math/tex&quot;&gt;{\lambda}&lt;/script&gt; and the re-estimation model by &lt;script type=&quot;math/tex&quot;&gt;\hat{\lambda}=(\hat{\pi}_i, \hat{a}_{ij},\hat{b}_j(k))&lt;/script&gt;. Then i t can be shown that either:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The initial model &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt; is a critical point of the likelihood in which case &lt;script type=&quot;math/tex&quot;&gt;\hat{\lambda}= \lambda&lt;/script&gt; or&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;P(Y \mid \hat\lambda) \leq P(Y \mid \lambda)&lt;/script&gt;, i.e we have find the better model from which the observation sequence &lt;script type=&quot;math/tex&quot;&gt;Y=y_1,\ldots Y_T&lt;/script&gt; is more likely to be produced.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Hence we can go on iteractively computing until &lt;script type=&quot;math/tex&quot;&gt;P(Y \mid \hat{\lambda})&lt;/script&gt; is maximazed.&lt;/p&gt;

&lt;p&gt;The Baum-Welch Algorithm can be summerized as:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Require&lt;/strong&gt;: &lt;script type=&quot;math/tex&quot;&gt;\lambda \leftarrow \lambda ^{init}&lt;/script&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt; &lt;strong&gt;repeat&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;  Compute the forward variable &lt;script type=&quot;math/tex&quot;&gt;\alpha _t(i)&lt;/script&gt; from the forward algorithm&lt;/li&gt;
  &lt;li&gt;  Compute the backward variable &lt;script type=&quot;math/tex&quot;&gt;\beta _t(i)&lt;/script&gt; from the backward algorithm&lt;/li&gt;
  &lt;li&gt;  Compute the occupation probabilities &lt;script type=&quot;math/tex&quot;&gt;\gamma _t(i)&lt;/script&gt;,  and &lt;script type=&quot;math/tex&quot;&gt;\xi _t(i,j)&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;  Estimate the new HMM parameters &lt;script type=&quot;math/tex&quot;&gt;\hat{\lambda}&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;  Update the HMM parameters   &lt;script type=&quot;math/tex&quot;&gt;\lambda \leftarrow \hat{\lambda}&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt; &lt;strong&gt;until&lt;/strong&gt; Convergence&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;L. R. Rabiner, &lt;a href=&quot;http://www.cs.ucsb.edu/~cs281b/papers/HMMs%20-%20Rabiner.pdf&quot;&gt;A tutorial on hidden Markov models and selected applications in speech recognition&lt;/a&gt;, Proceedings of the IEEE, Vol. 77, No. 2, February 1989.&lt;/li&gt;
  &lt;li&gt;Shinji Watanabe, Jen-Tzung Chien, &lt;a href=&quot;https://books.google.co.tz/books/about/Bayesian_Speech_and_Language_Processing.html?id=rEzzCQAAQBAJ&amp;amp;printsec=frontcover&amp;amp;source=kp_read_button&amp;amp;redir_esc=y#v=onepage&amp;amp;q&amp;amp;f=false&quot;&gt;Bayesian Speech and Language Processing&lt;/a&gt;, Cambridge University Press, 2015.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.vocal.com/echo-cancellation/viterbi-algorithm-in-speech-enhancement-and-hmm/&quot;&gt;Viterbi Algorithm in Speech Enhancement and HMM&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Nikolai Shokhirev, &lt;a href=&quot;http://www.shokhirev.com/nikolai/abc/alg/hmm/hmm.html&quot;&gt;Hidden Markov Models&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Anthony Faustine</name></author><summary type="html">In Previous post we discussed the basic of HMM modeling given model parameters and compute the likelihood values etc, efficiently based on the forward, backward, and Viterbi algorithms. In the like manner, we can efficiently train the HMM to obtain the model parameter from data. In this post we will discuss different methods for training HMM models.</summary></entry><entry><title type="html">The Basic of Hidden Markov Model</title><link href="http://localhost:4000/2017/05/03/hmm-intro.html" rel="alternate" type="text/html" title="The Basic of Hidden Markov Model" /><published>2017-05-03T00:00:00+02:00</published><updated>2017-10-01T19:21:51+02:00</updated><id>http://localhost:4000/2017/05/03/hmm-intro</id><content type="html" xml:base="http://localhost:4000/2017/05/03/hmm-intro.html">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;HMM is a Markov model whose states are not directly observed instead each state is characterised by a probability distribution function modelling the observation corresponding to that state. HMM has been extensively used in temporal pattern recognition such as speech, handwriting, gesture recognition, robotics, biological sequences and recently in energy disaggregation. This tutorial will introduce the basic concept of HMM.&lt;/p&gt;

&lt;p&gt;There are two variables in HMM: observed variables and hidden variables where the sequences of hidden variables forms a Markov process as shown in figure below. In the context of NILM, the hidden variables are used to model states(ON,OFF, standby etc) of individual appliances and the observed variables are used to model the electric usage. HMMs has been widely used in most of the recently proposed NILM approach because it represents well the individual appliance internal states which are not directly observed in the targeted energy consumption.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;/assets/img/post/hmm.png&quot; title=&quot;HMM graphical model&quot; alt=&quot;&quot; /&gt;
  &lt;figcaption&gt;HMM graphical model
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;A typical HMM is characterised by the following:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The finite set of hidden states  &lt;script type=&quot;math/tex&quot;&gt;S&lt;/script&gt; (e.g ON, stand-by, OFF, etc.) of an appliance,  &lt;script type=&quot;math/tex&quot;&gt;S = \{s_1, s_2....,s_N\}&lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;The finite set of  &lt;script type=&quot;math/tex&quot;&gt;M&lt;/script&gt; observable symbol  &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; per states (power consumption) observed in each state,  &lt;script type=&quot;math/tex&quot;&gt;Y = \{y_1, y_2....,y_M\}&lt;/script&gt;. The observable symbol  &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; can be discrete or a continuous set.&lt;/li&gt;
  &lt;li&gt;The transition matrix   &lt;script type=&quot;math/tex&quot;&gt;\mathbf{A}=\{a_{ij},1\leq i,j \geq N\}&lt;/script&gt; represents the probability of moving from state  &lt;script type=&quot;math/tex&quot;&gt;s_{t-1}=i&lt;/script&gt; to  &lt;script type=&quot;math/tex&quot;&gt;s_t =j&lt;/script&gt; such that:  &lt;script type=&quot;math/tex&quot;&gt;a_{ij} = P(s_{t} =j \mid s_{t-1}=i)&lt;/script&gt;, with  &lt;script type=&quot;math/tex&quot;&gt;a_{ij} \leq 0&lt;/script&gt; and where  &lt;script type=&quot;math/tex&quot;&gt;s_t&lt;/script&gt; denotes the state occupied by the system at time  &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt;. The matrix  &lt;script type=&quot;math/tex&quot;&gt;\mathbf{A}&lt;/script&gt; is  &lt;script type=&quot;math/tex&quot;&gt;N x N&lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;The emission matrix  &lt;script type=&quot;math/tex&quot;&gt;\mathbf{B} =\{b_j(k)\}&lt;/script&gt; representing the probability of emission of symbol  &lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt;  &lt;script type=&quot;math/tex&quot;&gt;\epsilon&lt;/script&gt;  &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; when system state is  &lt;script type=&quot;math/tex&quot;&gt;s_t=j&lt;/script&gt; such that:  &lt;script type=&quot;math/tex&quot;&gt;b_j(k) = p(y_t = k  \mid  s_t=j)&lt;/script&gt; The matrix  &lt;script type=&quot;math/tex&quot;&gt;\mathbf{B}&lt;/script&gt; is an  &lt;script type=&quot;math/tex&quot;&gt;N x M&lt;/script&gt;. The emission probability can be discrete or continous distribution. If the emission is descrete a multinomial distribution is used and multivariate Gaussian distribution is usually used for continous emission.&lt;/li&gt;
  &lt;li&gt;And the initial state probability distribution  &lt;script type=&quot;math/tex&quot;&gt;\bold{\pi}  = \{\pi_i \}&lt;/script&gt; indicating the probability of each state of the hidden variable  at  &lt;script type=&quot;math/tex&quot;&gt;t = 1&lt;/script&gt; such that,  &lt;script type=&quot;math/tex&quot;&gt;\pi _i = P(q_1 = s_i), 1 \leq i \geq N&lt;/script&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The complete HMM specification requires;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Finite set of hidden states &lt;script type=&quot;math/tex&quot;&gt;N&lt;/script&gt; and observation symbols &lt;script type=&quot;math/tex&quot;&gt;M&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;Length of observation seqences &lt;script type=&quot;math/tex&quot;&gt;T&lt;/script&gt; and&lt;/li&gt;
  &lt;li&gt;Specification of three probability measures &lt;script type=&quot;math/tex&quot;&gt;\mathbf{A}, \mathbf{B}&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\mathbf{\pi}&lt;/script&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The set of all HMM model parameters is represented by &lt;script type=&quot;math/tex&quot;&gt;\mathbf{\lambda} =(\pi, A, B)&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;Since &lt;script type=&quot;math/tex&quot;&gt;S&lt;/script&gt; is not observed, the likelihood function &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; is given by the joint distribution of &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;S&lt;/script&gt; over all possible state.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(Y \mid \lambda) = \sum P(Y, S \mid  \lambda)&lt;/script&gt;

&lt;p&gt;where&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(Y,S \mid \lambda) = P(Y \mid S,\lambda)P(S \mid \lambda)&lt;/script&gt;

&lt;p&gt;Note that &lt;script type=&quot;math/tex&quot;&gt;y_t&lt;/script&gt; is independent and identically distributed given state sequence &lt;script type=&quot;math/tex&quot;&gt;S = \{s_1, s_2....,s_N\}&lt;/script&gt;. Also each state at time &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt; depend on the state at its previous time &lt;script type=&quot;math/tex&quot;&gt;t-1&lt;/script&gt;. Then&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(Y \mid S, \lambda) = \prod_{t=1}^T P(y_t \mid s_t)&lt;/script&gt;

&lt;p&gt;Similary&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(S \mid \lambda) = \pi _{s_1} \prod _{t=2}^T a_{ij}&lt;/script&gt;

&lt;p&gt;The joint probability is therefore:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(Y \mid \lambda) = \pi _{s_1}P(y_1 \mid s_1) \sum \prod_{t=2}^T a_{ij} P(y_t \mid s_t)&lt;/script&gt;

&lt;h2 id=&quot;three-main-problems-in-hmms&quot;&gt;Three main problems in HMMs&lt;/h2&gt;

&lt;p&gt;When applying HMM to a real world problem, three important problem must be solved.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Evaluation Problem: Given HMM parameters &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt; and the observation seqence &lt;script type=&quot;math/tex&quot;&gt;Y = \{Y_1, Y_2....,Y_M\}&lt;/script&gt;, find &lt;script type=&quot;math/tex&quot;&gt;P(Y \mid \lambda)&lt;/script&gt; the likelihood of the observation sequence &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; given the model &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt;. This problem give a score on how well a given model matches a given observation and thus allows you to choose the model that best match the observation.&lt;/li&gt;
  &lt;li&gt;Decoding Problem: Given HMM parameters &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt; and the observation seqence &lt;script type=&quot;math/tex&quot;&gt;Y = \{Y_1, Y_2....,Y_M\}&lt;/script&gt;, find an optimal state sequense &lt;script type=&quot;math/tex&quot;&gt;S = \{S_1, S_2....,S_N\}&lt;/script&gt; which best explain the observation.This problem attempt to cover the hidden part of the model.&lt;/li&gt;
  &lt;li&gt;Learning Problem: Given the obseravtion seqence &lt;script type=&quot;math/tex&quot;&gt;Y = \{Y_1, Y_2....,Y_M\}&lt;/script&gt;, find the model parameters &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt; that maximize &lt;script type=&quot;math/tex&quot;&gt;P(Y \mid \lambda)&lt;/script&gt;.This problem attempt to optimize the model parameters so as to describe the model.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The first and the second problem can be solved by the dynamic programming algorithms known as the Viterbi algorithm and the Forward-Backward algorithm, respectively. The last one can be solved by an iterative Expectation-Maximization (EM) algorithm, known as the Baum-Welch algorithm. We will discuss the first and the second problem in this post.&lt;/p&gt;

&lt;h2 id=&quot;solution-to-problem-1&quot;&gt;Solution to Problem 1&lt;/h2&gt;

&lt;p&gt;A straight forward way to solve this problem is to find &lt;script type=&quot;math/tex&quot;&gt;P(Y \mid S, \lambda)&lt;/script&gt; for fixed state sequences &lt;script type=&quot;math/tex&quot;&gt;S = \{s_1,...s_T \}&lt;/script&gt; and then sum up over all possible states. This is generally infeasible since it requires about &lt;script type=&quot;math/tex&quot;&gt;2TN^T&lt;/script&gt; multiplications. However this problem can be efficiently solved by using the forward algorithm  as follows:&lt;/p&gt;

&lt;h3 id=&quot;the-forward-backward-algorithm&quot;&gt;The forward-backward Algorithm&lt;/h3&gt;

&lt;p&gt;Let us define the &lt;strong&gt;forward variable&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\alpha _t(i)=P(y_1,\ldots y_t, s_t=i \mid \lambda)&lt;/script&gt;

&lt;p&gt;the probability of the partial observation sequences &lt;script type=&quot;math/tex&quot;&gt;y_1 \ldots y_t&lt;/script&gt;  up to time &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt; and the state &lt;script type=&quot;math/tex&quot;&gt;s_t =i&lt;/script&gt; at time &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt; given the model &lt;script type=&quot;math/tex&quot;&gt;{\lambda}&lt;/script&gt;. We also define an emission probability given HMM state &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; at time &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt; as &lt;script type=&quot;math/tex&quot;&gt;b_i(y_t)&lt;/script&gt;.&lt;/p&gt;

&lt;h4 id=&quot;forward-algorithm&quot;&gt;Forward-Algorithm&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;Initilization&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Let&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\alpha _1(i)&amp;=P(y_1, s_1=i \mid \lambda) \\
    &amp; = P(y_1 \mid s_1=i,\lambda)P(s_1=i \mid \lambda)\\
    &amp;= \pi _i b_i(y_1) \text{  for  } 1\leq i \geq N
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Induction&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;For &lt;script type=&quot;math/tex&quot;&gt;t=2,3...T&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;1\leq i \geq N&lt;/script&gt;, compute:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\alpha _{t}(i) &amp; = P(y_1 \ldots y_t, s_t=i \mid \lambda)\\
 &amp;= \displaystyle \sum_{j=1}^{N} P(y_1 \ldots y_{t}, s_{t-1}=j,s_t=i \mid \lambda) \\
 &amp;= \displaystyle \sum_{j=1}^{N} P(y_t \mid s_t=i, y_1,\ldots y_{t-1}, s_{t-1}=j, \lambda) \\
   &amp;  \times P(s_t=i \mid y_1 \ldots y_{t-1} \ldots , s_{t-1}=j, \lambda) \\
   &amp; \times P(y_1 \ldots y_{t-1}, s_{t-1}=j,\lambda) \\
 &amp; = P(y_t \mid s_t=i,\lambda)\displaystyle \sum_{j=1}^{N} P(s_t=i \mid s_{t-1}=j)\cdot P(y_1, \ldots y_{t-1}, s_{t-1}) \\
&amp; = b_i(y_{t})\displaystyle \sum_{j=1}^{N} \alpha _{t-1}(i)a_{ij}  
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Termination&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;From &lt;script type=&quot;math/tex&quot;&gt;\alpha _t(i)=P(y_1,...y_t, s_t=i \mid \lambda)&lt;/script&gt;, it cear that:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned} 
P(Y \mid \lambda) &amp;= \displaystyle \sum_{i=1}^{N} P(y_1,\ldots y_T, s_T = i \mid \lambda) \\
&amp;= \displaystyle \sum_{i=1}^{N}\alpha _T(i)  
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;The forward algorithm only requires about &lt;script type=&quot;math/tex&quot;&gt;N^2T&lt;/script&gt; multiplications and is it can be implemented in python as follows.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;obs_seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;obs_seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;obs_seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;obs_seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;

 &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;likelihood&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;obs_seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;# returns log P(Y  \mid  model)&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;# using the forward part of the forward-backward algorithm&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;obs_seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;      
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;backward-algorithm&quot;&gt;Backward Algorithm&lt;/h3&gt;

&lt;p&gt;This is the same as the forward algorithm discussed in the previous sectionexcept that it start at the end and works backward toward the beginning. We first define the &lt;strong&gt;backward variable&lt;/strong&gt; &lt;script type=&quot;math/tex&quot;&gt;\beta_t(i)=P(y_{t+1},y_{t+2} \ldots y_{T} \mid s_t=i, {\lambda})&lt;/script&gt;: probability of the partial observed sequence from &lt;script type=&quot;math/tex&quot;&gt;t+1&lt;/script&gt; to the end at &lt;script type=&quot;math/tex&quot;&gt;T&lt;/script&gt; given state &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; at time &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt; and the model &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;Then &lt;script type=&quot;math/tex&quot;&gt;\beta_t(i)&lt;/script&gt; can be computed recursively as follows.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Initilization&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Let &lt;script type=&quot;math/tex&quot;&gt;\beta_{T}(i)= 1&lt;/script&gt;, for &lt;script type=&quot;math/tex&quot;&gt;1 \leq i\geq N&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Induction&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;For &lt;script type=&quot;math/tex&quot;&gt;t =T-1, T-2,\ldots1&lt;/script&gt; for &lt;script type=&quot;math/tex&quot;&gt;1 \leq i\geq N&lt;/script&gt; and by using the sum and product rules, we can rewrite &lt;script type=&quot;math/tex&quot;&gt;\beta_t(j)&lt;/script&gt; as:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\beta_t(i)&amp;=P(y_{t+1},\ldots y_{T} \mid s_t=j, {\lambda}) \\
 &amp;= \displaystyle \sum_{i=1}^{N} P(y_{t+1} \ldots y_T, s_{t+1}=i \mid s_t=j, \lambda) \\
 &amp; = \displaystyle \sum_{i=1}^{N} P(y_{t+1} \ldots y_T, s_{t+1}=i, s_t=j, \lambda)\cdot P(s_{t+1}=i \mid s_t=j) \\
 &amp;= \displaystyle \sum_{i=1}^{N} P(y_{t+2} \ldots y_T, s_{t+1}=i, \lambda)\cdot P(y_{t+1} \mid s_{t + 1}=i, \lambda)\cdot P(s_{t+1}=i \mid s_t=j) \\
 &amp; = \displaystyle \sum_{i=1}^{N} a_{ij}b_i(y_{t+1})\beta _{t+1}(i)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Termination&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\beta_{0} &amp; = P(Y \mid \lambda) \\
&amp; = \displaystyle \sum_{i=1}^{N} P(y_1,\ldots y_T, s_1=i) \\
&amp;= \displaystyle \sum_{i=1}^{N} P(y_1,\ldots y_T \mid s_1=i)\cdot P(s_1=i) \\
&amp; = \displaystyle \sum_{i=1}^{N} P(y_1 \mid s_1=i)\cdot P(y_2,\ldots y_T \mid s_1=i)\cdot P(s_1=i) \\
&amp; = \displaystyle \sum_{i=1}^{N} \pi _i b_i(y_1)\beta _1(i)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;Python implementation of forward algorithm is as shown below;&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;obs_seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;obs_seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;reversed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,:]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;obs_seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;posterior-probability&quot;&gt;Posterior Probability&lt;/h4&gt;
&lt;p&gt;The forward variable &lt;script type=&quot;math/tex&quot;&gt;\alpha _t(i)&lt;/script&gt; and backward variable &lt;script type=&quot;math/tex&quot;&gt;\beta _t(i)&lt;/script&gt; are used to calculate the posterior probability of a specific case. Now for &lt;script type=&quot;math/tex&quot;&gt;t=1...T&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;i=1..N&lt;/script&gt;, let define posterior probability &lt;script type=&quot;math/tex&quot;&gt;\gamma_t(i)=P(s_t=i \mid Y, \lambda)&lt;/script&gt; the probability of being in state &lt;script type=&quot;math/tex&quot;&gt;s_t = i&lt;/script&gt; at time &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt; given the observation &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; and the model &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt;.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\gamma_t(i) &amp; = \frac{P(s_t=1, Y \mid \lambda)}{P(Y \mid \lambda)} \\
 &amp;=\frac{P(y_1,\ldots y_t, s_t=1, \mid \lambda)}{P(Y \mid \lambda)}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;Consider:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
P(y_1,\ldots y_t, s_t=1, \mid \lambda) &amp; = P(y_1,\ldots y_t \mid  s_t=1,\lambda)\cdot P(y_{t+1},\ldots y_T \mid  s_t=1,\lambda)\cdot P(s_t =i  \mid \lambda) \\
 &amp; = \alpha _t(i) \cdot \beta _t(i)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;Thus&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\gamma_t(i) = \frac{\alpha _t(i) \cdot \beta _t(i)}{P(Y \mid \lambda)}&lt;/script&gt;

&lt;p&gt;where&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(Y \mid {\lambda}) =  \displaystyle \sum_{i=1}^{N}\alpha _T(i)&lt;/script&gt;

&lt;p&gt;In python:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;obs_seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;obs_seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;obs_seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;obs_prob&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;likelihood&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;obs_seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;obs_prob&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;We can use &lt;script type=&quot;math/tex&quot;&gt;\gamma_t(i)&lt;/script&gt; to find the most likely state at time &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt; which is the state &lt;script type=&quot;math/tex&quot;&gt;s_t=i&lt;/script&gt; for which &lt;script type=&quot;math/tex&quot;&gt;\gamma_t(i)&lt;/script&gt; is maximum. This algorithm &lt;a href=&quot;http://www.shokhirev.com/nikolai/abc/alg/hmm/hmm.html&quot;&gt;works fine in the case when HMM is ergodic&lt;/a&gt; i.e. there is transition from any state to any other state. If applied to an HMM of another architecture, this approach could give a sequence that may not be a legitimate path because some transitions are not permitted. To avoid this problem &lt;em&gt;Viterbi algorithm&lt;/em&gt; is the most common decoding algorithms used.&lt;/p&gt;

&lt;h3 id=&quot;viterbi-algorithm&quot;&gt;Viterbi Algorithm&lt;/h3&gt;

&lt;p&gt;Viterbi is a kind of dynamic programming algorithm that make uses of a dynamic programming trellis.&lt;/p&gt;

&lt;p&gt;The virtebi algorithm offer an efficient way of finding  the single best state sequence.Let define the highest probability along a single path, at time &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt;, which accounts for the first &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt; observations and ends in state &lt;script type=&quot;math/tex&quot;&gt;j&lt;/script&gt; using a new notation:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\delta_t(i) &amp; = \max_{s_1,\ldots s_{t-1}} P(s_1, \ldots s_t =1, y_1,\ldots y_t \mid \lambda)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;By induction, a recursive formula of &lt;script type=&quot;math/tex&quot;&gt;\delta_{t+1}(i)&lt;/script&gt; from &lt;script type=&quot;math/tex&quot;&gt;\delta_t(i)&lt;/script&gt;  is derived to calculate this probability as follows:&lt;/p&gt;

&lt;p&gt;Consider the joint distribution appearing in &lt;script type=&quot;math/tex&quot;&gt;\delta_{t+1}(i)&lt;/script&gt;, which can be rewritten when &lt;script type=&quot;math/tex&quot;&gt;s_{t+1}=i&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;s_t = j&lt;/script&gt; as:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
P(s_1,\ldots, s_t=j,s_{t+1}=i, y_1,\ldots y_t, y_{t+1} \mid \lambda) &amp; = P(s_1 \ldots s_t=j, y_1,\ldots y_t  \mid \lambda)\\&amp; \times P(s_{t+1}=i,y_{t+1} \mid s_1, \ldots s_t, y_1, \ldots y_t, \lambda) \\
 &amp; = P(s_1 \ldots s_t=j, y_1,\ldots y_t  \mid \lambda)\cdot P(s_{t+1} \mid s_t, \lambda)\\ &amp; \times P(y_{t+1} \mid s_{t+1},\lambda) \\
  &amp; = P(s_1 \ldots s_t=j, y_1,\ldots y_t  \mid \lambda)\cdot a_{ij}b_i(y_{t+1})
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;Thus &lt;script type=&quot;math/tex&quot;&gt;\delta_{t+1}(i)&lt;/script&gt;  is computed recursively from &lt;script type=&quot;math/tex&quot;&gt;\delta_{t+1}(j)&lt;/script&gt; as:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\delta_{t+1}(i) &amp;= \max_{s_1,\ldots s_{t}=j} P(s_1 \ldots s_t=j, y_1,\ldots y_t  \mid \lambda)\cdot a_{ij}b_i(y_{t+1}) \\
 &amp; = \max_{j}\Big[ \delta_t(j) a_{ij}\Big]\cdot b_i(y_{t+1})
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;We therefore need to keep track the state that maximize the above equation so as to backtrack to the single best state sequence in the following Viterbi algorithm:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Initilization&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;For &lt;script type=&quot;math/tex&quot;&gt;1 \leq i \geq N&lt;/script&gt;, let:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\delta _1(i)&amp;= \pi _{s_i}b_i(y_1)\\
\Theta _1(i)&amp;=0
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Recursion&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Calculate  the ML (maximum likelihood) state sequences and their probabilities. For &lt;script type=&quot;math/tex&quot;&gt;t=2,3,...T&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;1\leq i \geq N&lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}\delta_t(i) &amp; = \displaystyle \max_{j\epsilon{1,..N}} \Big[\delta_{t-1}(j)a_{ij}\Big]\cdot b_i(y_t) \\
\Theta_t(i) &amp; = \arg\max_j \Big[\delta_{t-1}(j)a_{ij} \Big] 
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Termination&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;Retrieve the most likely final state&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned} \hat{P} &amp;= \displaystyle \max_{j\epsilon{1,..N}}[\delta_T(j)]  \\
\hat{S}_T &amp; = \arg\max_j [\delta_T(j)]
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;State sequence backtracking&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;Retrieve  the most likely state sequences (virtebi path)&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{S}_t = \Theta_{t+1}(\hat{S}_{t+1}) \text{, where } t=T-1,T-2,\ldots1&lt;/script&gt;

&lt;p&gt;Virtebi algorithm uses the same schema as the Forward algorithm except for two differences:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;It uses maximization in place of summation at the recursion and termination steps.&lt;/li&gt;
  &lt;li&gt;It keeps track of the arguments that maximize &lt;script type=&quot;math/tex&quot;&gt;\delta_t(i)&lt;/script&gt; for each &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt;, storing them in the N by T matrix &lt;script type=&quot;math/tex&quot;&gt;\Theta&lt;/script&gt;. This matrix is used to retrieve the optimal state sequence at the backtracking step.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Python implementation of virtebi algorithm&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;viterbi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;obs_seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;# returns the most likely state sequence given observed sequence x&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;# using the Viterbi algorithm&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;obs_seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;psi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;obs_seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;obs_seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;psi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

        &lt;span class=&quot;c&quot;&gt;# backtrack&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;states&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;states&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;states&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;psi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;states&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;states&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;To summarize, we can compute the following from HMM:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The marginalized likelihood function &lt;script type=&quot;math/tex&quot;&gt;P(Y \mid \lambda)&lt;/script&gt; from the forward or backward algorithm.&lt;/li&gt;
  &lt;li&gt;The posterior probability &lt;script type=&quot;math/tex&quot;&gt;\gamma_t(i) = P(s_t=i  \mid Y, \lambda)&lt;/script&gt; from the forward–backward algorithm.&lt;/li&gt;
  &lt;li&gt;The optimal state sequence &lt;script type=&quot;math/tex&quot;&gt;\hat{S} = \max_{s} P(S \mid Y, \lambda) = \max_{s} P(S, Y \mid  \lambda)&lt;/script&gt;from the Viterbi algorithm.&lt;/li&gt;
  &lt;li&gt;The segmental joint likelihood function &lt;script type=&quot;math/tex&quot;&gt;P(\hat{S},Y \mid \lambda)&lt;/script&gt; from the Viterbi algorithm.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;These values are used in the decoding step and the training step of estimating model parameters &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Example 1&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Conside the Bob-Alice example as described &lt;a href=&quot;https://en.wikipedia.org/wiki/Hidden_Markov_model#A_concrete_example&quot;&gt;here&lt;/a&gt;. Two friends, Alice and Bob, who live far apart from each other and who talk together daily over the telephone about what they did that day. Bob is only interested in three activities: walking in the park, shopping, and cleaning his apartment. The choice of what to do is determined exclusively by the weather on a given day. Alice has no definite information about the weather where Bob lives, but she knows general trends. Based on what Bob tells her he did each day, Alice tries to guess what the weather must have been like.&lt;/p&gt;

&lt;p&gt;Alice believes that the weather operates as a discrete Markov chain. There are two states, “Rainy” and “Sunny”, but she cannot observe them directly, that is, they are hidden from her. On each day, there is a certain chance that Bob will perform one of the following activities, depending on the weather: “walk”, “shop”, or “clean”. Since Bob tells Alice about his activities, those are the observations.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;states&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Rainy'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'Sunny'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;observations&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'walk'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'shop'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'clean'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;#initial probability &lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;#Transmission probability &lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;B&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;#Emission probability&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Suppose Bob says walk, clean, shop, shop, clean, walk. What will Alice hears.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;bob_says&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;alice_hears&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;viterbi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bob_says&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Bob says:&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;, &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;observ_bob&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bob_says&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Alice hears:&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;, &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;states_bob&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alice_hears&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;blockquote&gt;
    ('Bob says:', 'walk, clean, shop, shop, clean, walk')
    ('Alice hears:', 'Sunny, Rainy, Rainy, Rainy, Rainy, Sunny')
&lt;/blockquote&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;L. R. Rabiner, &lt;a href=&quot;http://www.cs.ucsb.edu/~cs281b/papers/HMMs%20-%20Rabiner.pdf&quot;&gt;A tutorial on hidden Markov models and selected applications in speech recognition&lt;/a&gt;, Proceedings of the IEEE, Vol. 77, No. 2, February 1989.&lt;/li&gt;
  &lt;li&gt;Shinji Watanabe, Jen-Tzung Chien, &lt;a href=&quot;https://books.google.co.tz/books/about/Bayesian_Speech_and_Language_Processing.html?id=rEzzCQAAQBAJ&amp;amp;printsec=frontcover&amp;amp;source=kp_read_button&amp;amp;redir_esc=y#v=onepage&amp;amp;q&amp;amp;f=false&quot;&gt;Bayesian Speech and Language Processing&lt;/a&gt;, Cambridge University Press, 2015.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.vocal.com/echo-cancellation/viterbi-algorithm-in-speech-enhancement-and-hmm/&quot;&gt;Viterbi Algorithm in Speech Enhancement and HMM&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Nikolai Shokhirev, &lt;a href=&quot;http://www.shokhirev.com/nikolai/abc/alg/hmm/hmm.html&quot;&gt;Hidden Markov Models&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Anthony Faustine</name></author><summary type="html">Introduction</summary></entry><entry><title type="html">Introduction to Machine Learning - Classification.</title><link href="http://localhost:4000/ml/2017/04/15/ml-classification.html" rel="alternate" type="text/html" title="Introduction to Machine Learning - Classification." /><published>2017-04-15T17:12:00+02:00</published><updated>2017-10-01T19:21:51+02:00</updated><id>http://localhost:4000/ml/2017/04/15/ml-classification</id><content type="html" xml:base="http://localhost:4000/ml/2017/04/15/ml-classification.html">&lt;p&gt;Previously we learned how to predict continuous-valued quantities as a linear function of input values.This post will describe a classification probem where the goal is to learn a mapping from inputs &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; to target &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt; such that &lt;script type=&quot;math/tex&quot;&gt;t \in \{1\ldots C \}&lt;/script&gt; with with &lt;script type=&quot;math/tex&quot;&gt;C&lt;/script&gt; being the number of classes.If &lt;script type=&quot;math/tex&quot;&gt;C = 2&lt;/script&gt;, this is called binary classification (in which case we often assume &lt;script type=&quot;math/tex&quot;&gt;y \in \{0, 1\}&lt;/script&gt;; if &lt;script type=&quot;math/tex&quot;&gt;C &gt; 2&lt;/script&gt;, this is called multiclass classification.&lt;/p&gt;

&lt;p&gt;We will first consider binary classification problem in which the target classes &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt; will be generated from 2 class distributions: blue (&lt;script type=&quot;math/tex&quot;&gt;t=1&lt;/script&gt;) and red (&lt;script type=&quot;math/tex&quot;&gt;t=0&lt;/script&gt;). Samples from both classes are sampled from their respective distributions. These samples are plotted in the figure below.&lt;/p&gt;

&lt;p&gt;Note that &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; is a &lt;script type=&quot;math/tex&quot;&gt;N \times 2&lt;/script&gt; matrix of individual input samples &lt;script type=&quot;math/tex&quot;&gt;\mathbf{x}_i&lt;/script&gt;, and that &lt;script type=&quot;math/tex&quot;&gt;\mathbf{t}&lt;/script&gt; is a corresponding &lt;script type=&quot;math/tex&quot;&gt;N \times 1&lt;/script&gt; vector of target values &lt;script type=&quot;math/tex&quot;&gt;t_i&lt;/script&gt;.&lt;/p&gt;

&lt;h2 id=&quot;logistic-regression&quot;&gt;Logistic Regression&lt;/h2&gt;

&lt;p&gt;With logistic regression the goal is to predict the target class &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt; from the input values &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;. The network is defined as having an input &lt;script type=&quot;math/tex&quot;&gt;\mathbf{x} = [x_1, x_2]&lt;/script&gt; which gets transformed by the weights &lt;script type=&quot;math/tex&quot;&gt;\mathbf{w} = [w_1, w_2]&lt;/script&gt; to generate the probability that sample &lt;script type=&quot;math/tex&quot;&gt;\mathbf{x}&lt;/script&gt; belongs to class &lt;script type=&quot;math/tex&quot;&gt;t=1&lt;/script&gt;. This probability &lt;script type=&quot;math/tex&quot;&gt;P(t=1\mid \mathbf{x},\mathbf{w})&lt;/script&gt; is represented by the output &lt;script type=&quot;math/tex&quot;&gt;y&lt;/script&gt; of the network computed as &lt;script type=&quot;math/tex&quot;&gt;y = \sigma(\mathbf{x} * \mathbf{w}^T)&lt;/script&gt;. &lt;script type=&quot;math/tex&quot;&gt;\sigma&lt;/script&gt; is the &lt;a href=&quot;http://en.wikipedia.org/wiki/Logistic_function&quot;&gt;logistic function&lt;/a&gt; and is defined as:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sigma(z) = \frac{1}{1+e^{-z}}&lt;/script&gt;

&lt;p&gt;which squashes the predictions to be between 0 and 1 such that:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
P(t=1| \mathbf{x},\mathbf{w}) &amp;= y(\sigma(z))P(t=0\mid \mathbf{x},\mathbf{w})\\
 &amp;= 1 - P(t=1\mid \mathbf{x},\mathbf{w}) = 1 - y(\sigma(z))
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;The loss function for logistic function is called crossentropy and defined as:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{L}_{CE}(y,t)=\begin{cases} -\log y \quad \text{if } t = 1\\ -\log (1-y) \quad \text{if } t = 0
\end{cases}&lt;/script&gt;

&lt;p&gt;The crossentropy can be written in other form as:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{L}_{CE}(y,t)= -t \log y -(1-t)\log(1-y)&lt;/script&gt;

&lt;p&gt;When we combine the logistic activation function with cross-entropy loss, we get logistic regression:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
z &amp; = \mathbf{w^Tx + b}\\\ y &amp; = \sigma(z)\\\ \mathcal{L}_{CE}(y,t) &amp;= -t \log y -(1-t)\log(1-y)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;The cost function with respect to the model parameters &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt; (i.e. the weights and bias) is therefore:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\varepsilon_{\theta} &amp; = \frac{1}{N}\sum_{i=1}^N \mathcal{L}_{CE}(y,t)\\\ &amp; = \frac{1}{N}\sum_{i=1}^N \left(-t^{(i)} \log y^{(i)} -(1-t^{(i)})\log(1-y^{(i)})\right)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;which can be implemented in python as follows:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# Define the cost function&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multiply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multiply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;gradient-descent-for-logistic-function&quot;&gt;Gradient Descent for Logistic Function&lt;/h3&gt;

&lt;p&gt;To derive the gradient descent updates, we’ll need the partial derivatives of the cost function. We’ll do this by applying the Chain Rule twice: first to compute 
&lt;script type=&quot;math/tex&quot;&gt;\frac{\partial \mathcal{L}_{CE}}{\partial z}&lt;/script&gt; 
and then again to compute &lt;script type=&quot;math/tex&quot;&gt;\frac{\partial \mathcal{L}_{CE}}{\partial w_j}&lt;/script&gt; But first, let’s find 
&lt;script type=&quot;math/tex&quot;&gt;\frac{\partial y}{\partial z}&lt;/script&gt;.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\partial y}{ \partial z}  = \frac{e^{-z}}{(1 + e^{-z})^2}= y(1-y)&lt;/script&gt;

&lt;p&gt;Now for the Chain Rule:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\frac{\partial \mathcal{L}_{CE}}{\partial z} &amp; =\frac{\partial \mathcal{L}_{CE}}{\partial y}\frac{\partial y}{ \partial z}\\\ &amp; = \left(\frac{-t}{y} + \frac{1-t}{1-y}  \right) y(1-y)\\\ &amp;= y - t
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;Similary:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\frac{\partial \mathcal{L}_{CE}}{\partial w_j} &amp; =\frac{\partial \mathcal{L}_{CE}}{\partial z}\frac{\partial z}{ \partial w_j}\\\ &amp;  =\frac{\partial \mathcal{L}_{CE}}{\partial z} x_j\\\ &amp;= (y - t)x_j
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;We can also obtain &lt;script type=&quot;math/tex&quot;&gt;\frac{\partial \mathcal{L}_{CE}}{\partial b}&lt;/script&gt; as follows:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\frac{\partial \mathcal{L}_{CE}}{\partial b} &amp;= \frac{\partial \mathcal{L}_{CE}}{\partial z}\frac{\partial z}{\partial b}\\ &amp; = (y-t)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;The gradient descent algorithm works by taking the derivative of the cost function &lt;script type=&quot;math/tex&quot;&gt;\varepsilon_{\theta}&lt;/script&gt; with respect to the parameters, and updates the parameters in the direction of the negative gradient.The parameter &lt;script type=&quot;math/tex&quot;&gt;\mathbf{w}&lt;/script&gt; is iteratively updated by taking steps proportional to the negative of the gradient:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbf{w_{k+1}} = \mathbf{ w_k }- \alpha \frac{\partial \mathbf{\varepsilon}}{\partial \mathbf{w}}&lt;/script&gt;

&lt;p&gt;where:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\frac{\partial \mathcal{L}_{CE}}{\partial \varepsilon} &amp;= \frac{\partial \varepsilon }{\partial \mathcal{L}_{CE}}\cdot\frac{\partial \mathcal{L}_{CE}}{\partial \mathbf{w}}\\ &amp;= \frac{1}{N} \mathbf{x^T(y - t)}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;which can be implemented in python as follows:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#gradient&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;gradient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dw&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dw&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;

 &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;solve_gradient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e-2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;iterations&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;w_cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;dw&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gradient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;w_k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dw&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;w_cost&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;# Stopping Condition&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w_k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Converged.&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iterations&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Iteration: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;d - cost: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%.4&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;f&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iterations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;iterations&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w_k&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;   
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Let us apply the above concept in the following example. Consider the case we want to predict whether a student with certain pass mark can be admitted or not.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# load dataset&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;admission&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'data/admission.csv'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;names&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;grade1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;grade2&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;remark&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;admission&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The data-preprosessing is done using the following python code:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'grade1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'grade2'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'remark'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;targetVal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;admission&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;featureVal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;admission&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;targetVal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Standardize the features&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;featureVal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;featureVal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;featureVal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Add bias term to feature data&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;featureVal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hstack&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;featureVal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# randomly separate data into training and test data&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.model_selection&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_test_split&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_test_split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random_state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;    
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;We use the solve_gradient function defined before to find the parameter for logistic regression&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;w_g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;solve_gradient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.05&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1e-9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;Now that you learned the parameters of the model, you can use the model to predict whether a particular student will be admited.&lt;/p&gt;

&lt;p&gt;Let define the  prediction function that only  1 or 0 depending on the predicted class&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;around&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;To find the accuracy of the model:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;p_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w_g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;p_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w_g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Test Accuracy: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;f'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;where&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;100.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Train Accuracy: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;f'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;where&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;100.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;After running the above codes we found that our model achieve  a training accuracy of &lt;script type=&quot;math/tex&quot;&gt;91.25&lt;/script&gt; and a test accuracy of &lt;script type=&quot;math/tex&quot;&gt;85&lt;/script&gt; percents.&lt;/p&gt;

&lt;h2 id=&quot;multiclass-classification&quot;&gt;Multiclass classification&lt;/h2&gt;

&lt;p&gt;So far we’ve talked about binary classification, but most classifcation problems involve more than two categories. Fortunately, this doesn’t require any new ideas: everything pretty much works by analogy with the binary
case. The first question is how to represent the targets. We could represent them as integers, but it’s more convenient to use indicator vectors, or a one-of-K encoding.&lt;/p&gt;

&lt;p&gt;Since there are &lt;script type=&quot;math/tex&quot;&gt;K&lt;/script&gt; outputs and &lt;script type=&quot;math/tex&quot;&gt;D&lt;/script&gt; inputs, the linear function requires &lt;script type=&quot;math/tex&quot;&gt;K \times D&lt;/script&gt; matrix as well as &lt;script type=&quot;math/tex&quot;&gt;K&lt;/script&gt; dimensional bias vector. We use &lt;strong&gt;softmax function&lt;/strong&gt; which is the multivariate generalization given as:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;y_k =  softmax(z_1 \ldots z_k) = \frac{e^{z_k}}{\sum_k e^{z_k}}&lt;/script&gt;

&lt;p&gt;and can be implented in python as&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;softmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;e_x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Finally, the loss function (cross-entropy) for multiple-output case can be generalized as follows:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\mathcal{L}_{CE}(y,t) &amp;= -\sum_{k=1}^K t_k \log y_k\\ &amp;= -\mathbf{t^T}\log\mathbf{y}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;Combining these things together, we get multiclass logistic regression:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned} 
\mathbf{z} &amp;= \mathbf{wx + b} \\ \mathbf{y} &amp;= softmax(\mathbf{z})\\ \mathcal{L}_{CE}(y,t) &amp;=-\mathbf{t^T}\log\mathbf{y} \\
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;h2 id=&quot;gradient-descent-for-multiclass-logisitc-regression-for-multiclass-logistic-regression&quot;&gt;Gradient Descent for Multiclass Logisitc Regression for Multiclass logistic regression:&lt;/h2&gt;

&lt;p&gt;Let consider the derivative with respect to the loss:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\frac{\partial {\mathcal L}_\text{CE}}{\partial w_{kj}} &amp;= \frac{\partial }{\partial w_{kj}} \left(-\sum_l t_l \log(y_l)\right) \\ &amp;= -\sum_l \frac{t_l}{y_l} \frac{\partial y_l}{\partial w_{kj}}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;Normally in calculus we have the rule:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\frac{\partial y_l}{\partial w_{kj}} &amp;= \sum_m \frac{\partial y_l}{\partial z_m} \frac{\partial z_m}{\partial w_{kj}}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;But &lt;script type=&quot;math/tex&quot;&gt;w_{kj}&lt;/script&gt; is independent of &lt;script type=&quot;math/tex&quot;&gt;z_m&lt;/script&gt; for &lt;script type=&quot;math/tex&quot;&gt;m \ne k&lt;/script&gt;, so&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\frac{\partial y_l}{\partial w_{kj}} &amp;= \frac{\partial y_l}{\partial z_k} \frac{\partial z_k}{\partial w_{kj}}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;AND&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\partial z_k}{\partial w_{kj}} = x_j&lt;/script&gt;

&lt;p&gt;Thus&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\frac{\partial {\mathcal L}_\text{CE}}{\partial w_{kj}} &amp;=  -\sum_l \frac{t_l}{y_l} \frac{\partial y_l}{\partial z_k} \frac{\partial z_k}{\partial w_{kj}} \\
 &amp;= -\sum_l \frac{t_l}{y_l} \frac{\partial y_l}{\partial z_k} x_j \\
  &amp;= x_j (-\sum_l \frac{t_l}{y_l} \frac{\partial y_l}{\partial z_k}) \\
   &amp;= x_j \frac{\partial {\mathcal L}_\text{CE}}{\partial z_k} 
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;Now consider derivative with respect to &lt;script type=&quot;math/tex&quot;&gt;z_k&lt;/script&gt; we can show (on board) that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\partial y_l}{\partial z_k} = y_k (I_{k,l} - y_l)&lt;/script&gt;

&lt;p&gt;Where &lt;script type=&quot;math/tex&quot;&gt;I_{k,l} = 1&lt;/script&gt; if &lt;script type=&quot;math/tex&quot;&gt;k=l&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;0&lt;/script&gt; otherwise.&lt;/p&gt;

&lt;p&gt;Therefore&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\frac{\partial {\mathcal L}_\text{CE}}{\partial z_k} &amp;= -\sum_l \frac{t_l}{y_l} (y_k (I_{k,l} - y_l)) \\ &amp;=-\frac{t_k}{y_k} y_k(1 - y_k) - \sum_{l \ne k} \frac{t_l}{y_l} (-y_k y_l) \\
 &amp;= - t_k(1 - y_k) + \sum_{l \ne k} t_l y_k \\
  &amp;= -t_k + t_k y_k + \sum_{l \ne k} t_l y_k \\
   &amp;= -t_k + \sum_{l} t_l y_k \\
    &amp;= -t_k + y_k \sum_{l} t_l  \\
     &amp;= -t_k + y_k \\
      &amp;= y_k - t_k
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;Putting it all together&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\frac{\partial {\mathcal L}_\text{CE}}{\partial w_{kj}} &amp;= x_j (y_k - t_k)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;In vectorization form it become:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
\frac{\partial \mathcal {L}_{CE}}{\partial {\mathbf W}} = (\mathbf{y} - \mathbf{t}) \mathbf{x}^T 
\end{aligned}&lt;/script&gt;

&lt;h3 id=&quot;cross-entropy-cost-function&quot;&gt;Cross-entropy cost function&lt;/h3&gt;

&lt;p&gt;The cross entropy cost function for multiclass classification is given with respect to the model parameters &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt; (i.e. the weights and bias) is therefore:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\varepsilon_{\theta} &amp; = \frac{1}{N}\sum_{i=1}^N \mathcal{L}_{CE}(y,t)\\
 &amp; = \frac{-1}{N}\sum_{i=1}^N \sum_{k=1}^K t_k \log y_k
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;The gradient descent algorithm will be:
&lt;script type=&quot;math/tex&quot;&gt;\mathbf{w_{k+1}} = \mathbf{ w_k }- \alpha \frac{\partial \mathbf{\varepsilon}}{\partial \mathbf{w}}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;where:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\frac{\partial \mathcal{L}_{CE}}{\partial \varepsilon} &amp;= \frac{\partial \varepsilon }{\partial \mathcal{L}_{CE}}\cdot\frac{\partial \mathcal{L}_{CE}}{\partial \mathbf{w}}\\
 &amp;= \frac{1}{N} \mathbf{x^T(y - t)}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;The jupyter notebook for this post can be found &lt;a href=&quot;https://github.com/sambaiga/PythonML/blob/master/MLwithPython/Classification%20.ipynb&quot;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/&quot;&gt;CSC321 Intro to Neural Networks and Machine Learning&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://machinelearningmastery.com/supervised-and-unsupervised-machine-learning-algorithms/&quot;&gt;Supervised and Unsupervised Machine Learning Algorithms&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Anthony Faustine</name></author><summary type="html">Previously we learned how to predict continuous-valued quantities as a linear function of input values.This post will describe a classification probem where the goal is to learn a mapping from inputs to target such that with with being the number of classes.If , this is called binary classification (in which case we often assume ; if , this is called multiclass classification.</summary></entry><entry><title type="html">Introduction to Machine Learning</title><link href="http://localhost:4000/ml/2017/04/12/ml-intro.html" rel="alternate" type="text/html" title="Introduction to Machine Learning" /><published>2017-04-12T17:12:00+02:00</published><updated>2017-10-16T07:43:12+02:00</updated><id>http://localhost:4000/ml/2017/04/12/ml-intro</id><content type="html" xml:base="http://localhost:4000/ml/2017/04/12/ml-intro.html">&lt;h2 id=&quot;machine-learning&quot;&gt;Machine Learning&lt;/h2&gt;

&lt;h3 id=&quot;introduction&quot;&gt;Introduction&lt;/h3&gt;

&lt;p&gt;Machine learning is a set of algorithms that automatically detect patterns in data and use the uncovered pattern to make inferences or predictions. It is a subfield of artificial intelligence that aims to enable computers to learn on their own. Any machine learning algorithms involve the baisc three steps: first you identify pattern from data, then you build (train) model that best explain the pattern and the world (unseen data) and lastly use the model to predict or do inference. The process of training (building) a model can be seen as a learning process where the model is exposed to new, unfamiliar data step by step.&lt;/p&gt;

&lt;p&gt;Machine learning is an exciting and fast-moving field of computer science with many recent applications. Important applications where machine learning algorithms are regularly deployed includes:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Computer vision: Object Classification in Photograph, &lt;a href=&quot;https://petapixel.com/2016/09/23/googles-image-captioning-ai-can-describe-photos-94-accuracy/&quot;&gt;image captioning&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;Speech recognition, Automatic Machine Translation.&lt;/li&gt;
  &lt;li&gt;Detecting anomalies (e.g. Security, credit card fraud)&lt;/li&gt;
  &lt;li&gt;Speech recognition.&lt;/li&gt;
  &lt;li&gt;Communication systems&lt;sup&gt;&lt;a href=&quot;https://www.hhi.fraunhofer.de/en/departments/wn/research-groups/signal-and-information-processing/research-topics/machine-learning-and-data-mining-for-communication-systems.html&quot;&gt;ref&lt;/a&gt;&lt;sup&gt;&lt;/sup&gt;&lt;/sup&gt;&lt;/li&gt;
  &lt;li&gt;Robots learning complex behaviors&lt;/li&gt;
  &lt;li&gt;Recommendations services like in Amazo or Netflix where intelligent machine learning algorithms analyze your activity and compare it to the millions of other users to determine what you might like to buy or binge watch next&lt;sup&gt;&lt;a href=&quot;https://www.forbes.com/sites/bernardmarr/2016/09/30/what-are-the-top-10-use-cases-for-machine-learning-and-ai/#4f49a7d894c9&quot;&gt;ref&lt;/a&gt;&lt;/sup&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Machine learning algorithms that learn to recognise what they see and hear are at the heart of Apple, Google, Amazon, Facebook, Netflix, Microsoft, etc.&lt;/p&gt;

&lt;h3 id=&quot;why-machine-learning&quot;&gt;Why Machine learning&lt;/h3&gt;

&lt;p&gt;For many problems such as recognizing people and objects and understanding human speech  it’s difcult to program the correct behavior by hand. However with machine learning these taks are easier. Other reasons we might want to use machine learning to solve a given problem:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A system might need to adapt to a changing environment. For instance, spammers are constantly trying to figure out ways to trick our e-mail spam classifers, so the classifcation algorithms will need to constantly adapt.&lt;/li&gt;
  &lt;li&gt;A learning algorithm might be able to perform better than its human programmers. Learning algorithms have become world champions at a variety of games, from checkers to chess to Go. This would be impossible if the programs were only doing what they were explicitly told to.&lt;/li&gt;
  &lt;li&gt;We may want an algorithm to behave autonomously for privacy or fairness reasons, such as with ranking search results or targeting ads.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;types-of-machine-learning&quot;&gt;Types of Machine Learning&lt;/h3&gt;

&lt;p&gt;Machine learning is usually divide into three  major  types: Supervised Learning, Unspervised Learning and&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Supervised Learning&lt;/strong&gt;: Supervised learning is where you have input variables x and an output variable y and you use an algorithm to learn the mapping function from the input to the output&lt;sup&gt;&lt;a href=&quot;http://machinelearningmastery.com/supervised-and-unsupervised-machine-learning-algorithms/&quot;&gt;ref&lt;/a&gt;&lt;/sup&gt;. For instance, if we’re trying to train a machine leearning algorithm to distinguish cars and trucks, we would collect images of cars and trucks, and label each one as a car or a truck. Supervised learning problems can be further grouped into regression and classification problems.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;A regression problem&lt;/strong&gt;: is when the output variable is a real value, such as “dollars” or “weight” e.g Linear regression and Random forest.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Classification&lt;/strong&gt;: A classification problem is when the output variable is a category, such as “red” or “blue” or “disease” and “no disease” e.g Support vector machines, Random forest and logistic regression.
 Some popular examples of supervised machine learning algorithms are:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Unspervised Learning&lt;/strong&gt; :Unsupervised learning is where you only have input data (X) and no corresponding output variables.We just have a bunch of data, and want to look for patterns in the data. For instance, maybe we have lots of examples of patients with autism, and want to identify different subtypes of the condition.The most important types of unsupervised learning includes:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Distribution modeling&lt;/strong&gt; where one has an unlabeled dataset (such as a collection of images or sentences), and the goal is to learn a probability distribution which matches the dataset as closely as possible.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Clustering&lt;/strong&gt; where the aim is to discover the inherent groupings in the data, such as grouping customers by purchasing behavior.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Reiforcement Learning&lt;/strong&gt;: is &lt;a href=&quot;https://www.oreilly.com/ideas/reinforcement-learning-explained&quot;&gt;learning best actions based on reward or punishment&lt;/a&gt;. It involves learning what actions to take in a given situation, based on &lt;em&gt;rewards&lt;/em&gt;
and &lt;em&gt;penalties&lt;/em&gt;. Example a robot takes a big step forward, then falls. The next time, it takes a smaller step and is able to hold its balance. The robot tries variations like this many times; eventually, it learns the right size of steps to take and walks steadily. It has succeeded.&lt;/p&gt;

&lt;p&gt;There are three basic concepts in reinforcement learning: state, action, and reward. The state describes the current situation. Action is what an agent can do in each state. When a robot takes an action in a state, it receives a reward, a feedback from the environment. A reward can be positive or negative (penalties).&lt;/p&gt;

&lt;h2 id=&quot;typical-ml-task-linear-regression&quot;&gt;Typical ML task: Linear Regression&lt;/h2&gt;

&lt;p&gt;In regression, we are interested in predicting a scalar-valued target, such as the price of a stock. By linear, we mean that the target must be predicted as a linear function of the inputs. This is a kind of supervised learning algorithm; recall that, in supervised learning, we have a collection of training examples labeled with the correct outputs. Example applications of linear regression include weather forecasting, house pricing prediction, student performance (GPA) prediction just to mention a few.&lt;/p&gt;

&lt;h3 id=&quot;linear-regression-formulating-a-learning-problem&quot;&gt;Linear Regression: Formulating a learning problem&lt;/h3&gt;
&lt;p&gt;In order to formulate a learning problem mathematically, we need to define two things: a &lt;em&gt;model (hypothesis)** and a *loss function&lt;/em&gt;. After defining model and loss function we solve an optimisation problem with the aim to find the model parameters that best fit the data.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Model (Hypothesis)&lt;/strong&gt;: It is the set of allowable hypotheses, or functions that compute predictions from the inputs. In the case of linear regression, the model simply consists of linear functions given by:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;y = \sum_j w_jx_j + b&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;w&lt;/script&gt; is the weights, and &lt;script type=&quot;math/tex&quot;&gt;b&lt;/script&gt; is an intercept term, which we’ll call the bias. These two terms are called model parameters denoted as &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Loss function&lt;/strong&gt;: It defines how well the model fit the data and thus show how far off the prediction &lt;script type=&quot;math/tex&quot;&gt;y&lt;/script&gt; is from the target &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt; and given as:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{L(y,t)} = \frac{1}{2}(y - t)^2&lt;/script&gt;

&lt;p&gt;Since the loss function show how far off the prediction is from the target for one data point. We also need to define a cost function. The cost function is simply the loss, averaged over all the training examples.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned} 
J (w_1\ldots w_D,b) &amp; = \frac{1}{N} \sum_{i=1}^N \mathcal{L}(y^{(i)},t^{(i)}) \\
 &amp; = \frac{1}{2N}\sum_{i=1}^N (y^{(i)} - t^{(i)})^2 \\
 &amp;=\frac{1}{2N}\sum_{i=1}^N \left(\sum_j w_jx_j^{(i)} + b -t^{(i)} \right)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;In vectorized form:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbf{J} =\frac{1}{2N} \lVert\mathbf{y-t}\lVert^2 =\frac{1}{2N}\mathbf{(y - t)^T(y-t)} \quad \text{where}\quad \mathbf{y = w^Tx}&lt;/script&gt;

&lt;p&gt;The python implementation of the cost function (vectorized) is shown below.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matmul&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'''
    Evaluate the cost function in a vectorized manner for 
    inputs `x` and targets `t`, at weights `w1`, `w2` and `b`.
    '''&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;2.0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;    
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Combine our model and loss function, we get an optimization problem, where we are trying to minimize a cost function with respect to the model parameters &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt; (i.e. the weights and bias).&lt;/p&gt;

&lt;h2 id=&quot;solving-the-optimization-problem&quot;&gt;Solving the optimization problem&lt;/h2&gt;
&lt;p&gt;We now want to find the choice of model parameters &lt;script type=&quot;math/tex&quot;&gt;\theta _{w_1\ldots w_D,b}&lt;/script&gt; that minimizes &lt;script type=&quot;math/tex&quot;&gt;J (w_1\ldots w_D,b)&lt;/script&gt; as given in the cost function above.There are two methods which we can use: direct solution and gradient descent.&lt;/p&gt;

&lt;h3 id=&quot;direct-solution&quot;&gt;Direct Solution&lt;/h3&gt;
&lt;p&gt;One way to compute the minimum of a function is to set the partial derivatives to zero.For simplicity, let’s assume the model doesn’t have a bias term as shown in the equation below.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;J_\theta =\frac{1}{2N}\sum_{i=1}^N \left(\sum_j w_jx_j^{(i)}  -t^{(i)} \right)&lt;/script&gt;

&lt;p&gt;In vectorized form&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbf{J} =\frac{1}{2N}\lVert \mathbf{y-t}\rVert ^2 \frac{1}{2N}\mathbf{(y - t)^T(y-t)}  \quad \text{where}\quad \mathbf{y = wx}&lt;/script&gt;

&lt;p&gt;For matrix differentiation we need the following results:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
 \frac{\partial \mathbf{Ax}}{\partial \mathbf{x}} &amp; = \mathbf{A}^T \frac{\partial (\mathbf{x}^T\mathbf{Ax})}{\partial \mathbf{x}}\\ &amp; = 2\mathbf{A}^T\mathbf{x}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;Setting the partial derivatives of cost function in vectorized form to zero we obtain:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}\frac{\partial \mathbf{J}}{\partial \mathbf{w}} &amp; =\frac{1}{2N}\frac{\partial \left(\mathbf{w^Tx^Tx w} -2 \mathbf{t^Twx} + \mathbf{t^Tt}\right)}{\partial \mathbf{w}} \\
&amp;=\frac{1}{2N}\left(2\mathbf{x}^T\mathbf{xw} -2\mathbf{x}^T\mathbf{t}\right) \\
\mathbf{w} &amp;= (\mathbf{x^Tx})^{-1}\mathbf{x^Tt}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;In python this result can be implemented as follows:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;directMethod&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'''
    Solve linear regression exactly. (fully vectorized)
    
    Given `x` - NxD matrix of inputs
          `t` - target outputs
    Returns the optimal weights as a D-dimensional vector
    '''&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matmul&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matmul&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linalg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;gradient-descent&quot;&gt;Gradient Descent&lt;/h2&gt;

&lt;p&gt;The optimization algorithm commonly used to train machine learning is the gradient descent algorithm. It works by taking the derivative of the cost function &lt;script type=&quot;math/tex&quot;&gt;J&lt;/script&gt; with respect to the parameters at a specific position on this cost function, and updates the parameters in the direction of the negative gradient. The entries of the gradient vector are simply the partial derivatives with respect to each of the variables:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\partial \mathbf{J}}{\partial \mathbf{w}} = \begin{pmatrix} \frac{\partial J}{\partial w_1}\\
 \vdots\\ \frac{\partial J}{\partial w_D}
\end{pmatrix}&lt;/script&gt;

&lt;p&gt;The parameter &lt;script type=&quot;math/tex&quot;&gt;\mathbf{w}&lt;/script&gt; is iteratively updated by taking steps proportional to the negative of the gradient:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbf{w_{t+1}} = \mathbf{ w_t }- \alpha \frac{\partial \mathbf{J}}{\partial \mathbf{w}}  = \mathbf{w_t} - \mathbf{\frac{\alpha}{N}x^T(y-t)}&lt;/script&gt;

&lt;p&gt;In coordinate systems this is equivalent to:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;w_{t+1} = w_t - \alpha \frac{1}{N}\sum_{i=1}^{N} x_t (y^{(i)}-t^{(i)})&lt;/script&gt;

&lt;p&gt;The python implementation of gradient descent is shown below:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;getGradient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matmul&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transpose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gradient&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;gradientDescentMethod&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e-2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;#w = np.random.randn(D)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# Perform Gradient Descent&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;iterations&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;w_cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;dw&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;getGradient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;w_k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dw&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;w_cost&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;# Stopping Condition&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w_k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Converged.&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iterations&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Iteration: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;d - cost: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%.4&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;f&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iterations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;iterations&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w_k&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w_cost&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;generalization&quot;&gt;Generalization&lt;/h2&gt;

&lt;p&gt;The goal of a learning algorithm is not to only to make correct predictions on the training examples; but it should be generalized to examples not seen seen before. The average squared error on novel examples is known as the generalization error, and we’d like this to be as small as possible. In practice, we nor- mally tune model parameters by partitioning the dataset into three different subsets:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The training set is used to train the model.&lt;/li&gt;
  &lt;li&gt;The validation set is used to estimate the generalization error of each hyperparameter setting.&lt;/li&gt;
  &lt;li&gt;The test set is used at the very end, to estimate the generalization error of the final model, once all hyperparameters have been chosen.&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Anthony Faustine</name></author><summary type="html">Machine Learning</summary></entry></feed>